{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fantasy Baseball Optimization\n",
    "*Allyson Tom, Drew Pearson, Jacob Adams*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need two subsets of data for this portion of our dataset: hitter data and pitcher data.\n",
    "\n",
    "### Hitter Data\n",
    "We will first create a pandas DataFrame that holds the following hitting statistics for players for the 2010 through 2016 seasons:\n",
    "- Player Name\n",
    "- Player Age\n",
    "- Doubles (2B)\n",
    "- Triples (3B)\n",
    "- Runs (R)\n",
    "- Homeruns (HR)\n",
    "- Walks (BB)\n",
    "- Strikeouts (SO)\n",
    "- Runs Batted In (RBI)\n",
    "- Stolen Bases (SB)\n",
    "- Batting Average (AVG)\n",
    "- On-Base Percentage (OBP)\n",
    "- Slugging Percentage (SLG)\n",
    "- Season/Year\n",
    "- At Bats (AB)\n",
    "- Position (Pos Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ================================== CREATE DATAFRAME OF ALL HITTER INFORMATION =====================================\n",
    "\n",
    "# empty list to append to for each year of information\n",
    "hittersDF = []\n",
    "# list of years to loop through\n",
    "year_list = [2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009]\n",
    "for year in year_list:\n",
    "    # open the file PlayerData/2016Hitters (or whatever year)\n",
    "    with open('CSV_files/PlayerData/' + str(year)+'Hitters') as inFile:\n",
    "        # convert csv file to pandas DataFrame, specifying datatypes\n",
    "        DF2016 = pd.read_csv(inFile)\n",
    "        # create year column\n",
    "        DF2016[\"Year\"] = year\n",
    "        # append to master list\n",
    "        hittersDF.append(DF2016)\n",
    "#concatenate master list into pandas DataFrame\n",
    "hittersDF = pd.concat(hittersDF)\n",
    "\n",
    "# remove all except columns of interest for our particular project (files have more stats than we are interested in)\n",
    "hittersDF = hittersDF[[\"Name\", \"Age\", \"2B\", \"3B\", \"BB\", \"SO\", \"OBP\", \"SLG\", \"Tm\", \"R\", \"HR\", \"RBI\", \"SB\", \"BA\", \\\n",
    "                       \"AB\", \"Pos Summary\", \"Year\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the hitting data in a Pandas DataFrame, we need to clean it. Right now, we have 10,766 rows and 10 columns in our hitters DataFrame. Before we get into the cleaning, here is a sample of what the hittersDF looks like, and the null values that we have at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>Tm</th>\n",
       "      <th>R</th>\n",
       "      <th>HR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>BA</th>\n",
       "      <th>AB</th>\n",
       "      <th>Pos Summary</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fernando Abad*\\abadfe01</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>TOT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fernando Abad*\\abadfe01</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fernando Abad*\\abadfe01</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jose Abreu\\abreujo02</td>\n",
       "      <td>29</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.468</td>\n",
       "      <td>CHW</td>\n",
       "      <td>67.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.293</td>\n",
       "      <td>624.0</td>\n",
       "      <td>*3/D</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.J. Achter\\achteaj01</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name  Age    2B   3B    BB     SO    OBP    SLG   Tm  \\\n",
       "0  Fernando Abad*\\abadfe01   30   0.0  0.0   0.0    1.0  0.000  0.000  TOT   \n",
       "1  Fernando Abad*\\abadfe01   30   0.0  0.0   0.0    1.0  0.000  0.000  MIN   \n",
       "2  Fernando Abad*\\abadfe01   30   0.0  0.0   0.0    0.0    NaN    NaN  BOS   \n",
       "3     Jose Abreu\\abreujo02   29  32.0  1.0  47.0  125.0  0.353  0.468  CHW   \n",
       "4    A.J. Achter\\achteaj01   27   0.0  0.0   0.0    0.0    NaN    NaN  LAA   \n",
       "\n",
       "      R    HR    RBI   SB     BA     AB Pos Summary  Year  \n",
       "0   0.0   0.0    0.0  0.0  0.000    1.0           1  2016  \n",
       "1   0.0   0.0    0.0  0.0  0.000    1.0           1  2016  \n",
       "2   0.0   0.0    0.0  0.0    NaN    0.0           1  2016  \n",
       "3  67.0  25.0  100.0  0.0  0.293  624.0        *3/D  2016  \n",
       "4   0.0   0.0    0.0  0.0    NaN    0.0           1  2016  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hittersDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name              0\n",
      "Age               0\n",
      "2B              139\n",
      "3B              139\n",
      "BB              139\n",
      "SO              139\n",
      "OBP            3472\n",
      "SLG            3507\n",
      "Tm                0\n",
      "R               139\n",
      "HR              139\n",
      "RBI             139\n",
      "SB              139\n",
      "BA             3507\n",
      "AB              139\n",
      "Pos Summary      37\n",
      "Year              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print hittersDF.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, there are a few issues with our DataFrame as it currently stands. We decided that we would record names in all lowercase letters for uniformity; there are also symbols and letters appearing in the Name column that need to be removed. There are several players who have more than one row because they were traded mid-way through a season. For that reason, we drop all rows that are not the player's total for the given year. We also wanted to create a name column that has first initial and last name for later use. Finally, we remove all pitchers from the hitters dataframe and we limit the hitters dataframe to only players with more than 200 at bats in a given season. We will address these issues in the code that follows.\n",
    "\n",
    "Note: We keep player position for later use. The symbols denote the following:\n",
    "- \\* indicates the player played 2/3 or more of the season there\n",
    "- positions after \\ indicate that a player played less than 10 games there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions that will be used to separate Names into 'First' and 'Last' name columms\n",
    "def lower_names(string):\n",
    "    split_string = string.split(',')\n",
    "    return str.lower(split_string[0])\n",
    "def split_names_first(string):\n",
    "    split_string = string.split(' ')\n",
    "    first = str.lower(split_string[0])\n",
    "    return first\n",
    "def split_names_first_initial(string):\n",
    "    split_string = string.split(' ')\n",
    "    first = str.lower(list(split_string[0])[0]) + '.'\n",
    "    return first\n",
    "def split_names_last(string):\n",
    "    split_string = string.split(' ')\n",
    "    last = str.lower(' '.join(split_string[1:]))\n",
    "    return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace names with corrected version by removing the unnecessary portions that appear in the DF above\n",
    "hittersDF['Name'] = hittersDF['Name'].str.replace(r'[*|\\\\|#|\\+].*', '')\n",
    "# change all letters in names to lower case\n",
    "hittersDF['Name'] = hittersDF['Name'].apply(lower_names)\n",
    "# create columns separating out pieces of player names\n",
    "hittersDF['First'], hittersDF['First_initial'], hittersDF['Last'] = \\\n",
    "        hittersDF['Name'].apply(split_names_first),hittersDF['Name'].apply(split_names_first_initial),\\\n",
    "        hittersDF['Name'].apply(split_names_last)\n",
    "hittersDF['Abbr_Name'] = hittersDF['First_initial'] + ' ' + hittersDF['Last']\n",
    "del hittersDF['First'], hittersDF['First_initial'], hittersDF['Last']\n",
    "\n",
    "# drop duplicates - keep first occurence, which is the one we want (total)\n",
    "for yr in year_list:\n",
    "    hittersDF[hittersDF[\"Year\"] == yr] = hittersDF[hittersDF[\"Year\"] == yr].drop_duplicates('Name')\n",
    "\n",
    "# drop rows with null values in the Name column\n",
    "hittersDF = hittersDF.dropna(subset = [\"Name\"], axis=0)\n",
    "# drop Team column\n",
    "hittersDF = hittersDF.drop(\"Tm\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop players with position = '1' (pitchers)\n",
    "hittersDF = hittersDF[(hittersDF[\"Pos Summary\"] != \"1\") & (hittersDF[\"Pos Summary\"] != \"/1\")]\n",
    "\n",
    "# drop player with fewer than 200 at-bats\n",
    "hittersDF = hittersDF[hittersDF[\"AB\"] > 200]\n",
    "# Reset the index values\n",
    "hittersDF = hittersDF.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign columns the correct datatypes\n",
    "\n",
    "hittersDF[\"Name\"] = hittersDF[\"Name\"].astype(str)\n",
    "hittersDF[\"R\"] = hittersDF[\"R\"].astype(int)\n",
    "hittersDF[\"HR\"] = hittersDF[\"HR\"].astype(int)\n",
    "hittersDF[\"RBI\"] = hittersDF[\"RBI\"].astype(int)\n",
    "hittersDF[\"SB\"] = hittersDF[\"SB\"].astype(int)\n",
    "hittersDF[\"AB\"] = hittersDF[\"AB\"].astype(int)\n",
    "hittersDF[\"Pos Summary\"] = hittersDF[\"Pos Summary\"].astype(str)\n",
    "hittersDF[\"Year\"] = hittersDF[\"Year\"].astype(int)\n",
    "hittersDF[\"Abbr_Name\"] = hittersDF[\"Abbr_Name\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of these corrections, our hitters dataframe is ready to use. We now have 2,313 rows and 9 columns. Here is a cleaned sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2647, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>R</th>\n",
       "      <th>HR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>BA</th>\n",
       "      <th>AB</th>\n",
       "      <th>Pos Summary</th>\n",
       "      <th>Year</th>\n",
       "      <th>Abbr_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jose abreu</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.468</td>\n",
       "      <td>67</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.293</td>\n",
       "      <td>624</td>\n",
       "      <td>*3/D</td>\n",
       "      <td>2016</td>\n",
       "      <td>j. abreu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cristhian adames</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.302</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.218</td>\n",
       "      <td>225</td>\n",
       "      <td>645</td>\n",
       "      <td>2016</td>\n",
       "      <td>c. adames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matt adams</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.471</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249</td>\n",
       "      <td>297</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>m. adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nick ahmed</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.299</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.218</td>\n",
       "      <td>284</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>n. ahmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yonder alonso</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.367</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>0.253</td>\n",
       "      <td>482</td>\n",
       "      <td>*3/5D</td>\n",
       "      <td>2016</td>\n",
       "      <td>y. alonso</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name   Age    2B   3B    BB     SO    OBP    SLG   R  HR  RBI  \\\n",
       "0        jose abreu  29.0  32.0  1.0  47.0  125.0  0.353  0.468  67  25  100   \n",
       "1  cristhian adames  24.0   7.0  3.0  24.0   47.0  0.304  0.302  25   2   17   \n",
       "2        matt adams  27.0  18.0  0.0  25.0   81.0  0.309  0.471  37  16   54   \n",
       "3        nick ahmed  26.0   9.0  1.0  15.0   58.0  0.265  0.299  26   4   20   \n",
       "4     yonder alonso  29.0  34.0  0.0  45.0   74.0  0.316  0.367  52   7   56   \n",
       "\n",
       "   SB     BA   AB Pos Summary  Year  Abbr_Name  \n",
       "0   0  0.293  624        *3/D  2016   j. abreu  \n",
       "1   2  0.218  225         645  2016  c. adames  \n",
       "2   0  0.249  297           3  2016   m. adams  \n",
       "3   5  0.218  284           6  2016   n. ahmed  \n",
       "4   3  0.253  482       *3/5D  2016  y. alonso  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print hittersDF.shape\n",
    "hittersDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table of some basic summary statistics for the dataset of actual hitter statistics as well, followed by a sum of null values to demonstrate that they have all been handled. It can also be seen from the summary statistics that nothing seems out of range, and the values reported make sense given the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>R</th>\n",
       "      <th>HR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>BA</th>\n",
       "      <th>AB</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "      <td>2647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.687193</td>\n",
       "      <td>21.826974</td>\n",
       "      <td>2.306385</td>\n",
       "      <td>39.010956</td>\n",
       "      <td>86.077824</td>\n",
       "      <td>0.326362</td>\n",
       "      <td>0.413285</td>\n",
       "      <td>54.970533</td>\n",
       "      <td>13.042312</td>\n",
       "      <td>52.760484</td>\n",
       "      <td>7.652437</td>\n",
       "      <td>0.260409</td>\n",
       "      <td>416.784662</td>\n",
       "      <td>2012.499056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.003730</td>\n",
       "      <td>9.590062</td>\n",
       "      <td>2.405314</td>\n",
       "      <td>20.582179</td>\n",
       "      <td>34.609177</td>\n",
       "      <td>0.035790</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>23.763302</td>\n",
       "      <td>9.401381</td>\n",
       "      <td>25.433269</td>\n",
       "      <td>9.767483</td>\n",
       "      <td>0.031363</td>\n",
       "      <td>130.942264</td>\n",
       "      <td>2.292463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>0.349000</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>0.474000</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>684.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age           2B           3B           BB           SO  \\\n",
       "count  2647.000000  2647.000000  2647.000000  2647.000000  2647.000000   \n",
       "mean     28.687193    21.826974     2.306385    39.010956    86.077824   \n",
       "std       4.003730     9.590062     2.405314    20.582179    34.609177   \n",
       "min      19.000000     2.000000     0.000000     4.000000    21.000000   \n",
       "25%      26.000000    14.000000     1.000000    24.000000    60.000000   \n",
       "50%      28.000000    21.000000     2.000000    35.000000    81.000000   \n",
       "75%      31.000000    28.000000     3.000000    51.000000   107.000000   \n",
       "max      43.000000    56.000000    16.000000   143.000000   223.000000   \n",
       "\n",
       "               OBP          SLG            R           HR          RBI  \\\n",
       "count  2647.000000  2647.000000  2647.000000  2647.000000  2647.000000   \n",
       "mean      0.326362     0.413285    54.970533    13.042312    52.760484   \n",
       "std       0.035790     0.069297    23.763302     9.401381    25.433269   \n",
       "min       0.174000     0.187000     4.000000     0.000000     8.000000   \n",
       "25%       0.303000     0.365000    36.000000     6.000000    32.000000   \n",
       "50%       0.325000     0.409000    52.000000    11.000000    49.000000   \n",
       "75%       0.349000     0.457000    72.000000    18.000000    70.000000   \n",
       "max       0.474000     0.658000   136.000000    54.000000   141.000000   \n",
       "\n",
       "                SB           BA           AB         Year  \n",
       "count  2647.000000  2647.000000  2647.000000  2647.000000  \n",
       "mean      7.652437     0.260409   416.784662  2012.499056  \n",
       "std       9.767483     0.031363   130.942264     2.292463  \n",
       "min       0.000000     0.146000   201.000000  2009.000000  \n",
       "25%       1.000000     0.240000   298.000000  2010.000000  \n",
       "50%       4.000000     0.260000   417.000000  2013.000000  \n",
       "75%      11.000000     0.282000   532.000000  2014.000000  \n",
       "max      70.000000     0.365000   684.000000  2016.000000  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hittersDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name           0\n",
      "Age            0\n",
      "2B             0\n",
      "3B             0\n",
      "BB             0\n",
      "SO             0\n",
      "OBP            0\n",
      "SLG            0\n",
      "R              0\n",
      "HR             0\n",
      "RBI            0\n",
      "SB             0\n",
      "BA             0\n",
      "AB             0\n",
      "Pos Summary    0\n",
      "Year           0\n",
      "Abbr_Name      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print hittersDF.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that after cleaning our hitters data we do not have any null values. We did not deliberately drop na values, but we did drop pitchers and players that will not add value in the scope of this project. As a result we have a nice clean dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitcher Data\n",
    "\n",
    "We now create a pandas DataFrame that holds the following pitching statistics for players (pitchers only) for the 2010 through 2016 seasons:\n",
    "- Player Name\n",
    "- Strikeouts (K)\n",
    "- Wins (W)\n",
    "- Saves (SV)\n",
    "- Earned Run Average (ERA)\n",
    "- Walks plus Hits per Inning Pitched (WHIP)\n",
    "- Season/Year\n",
    "- Innings Pitched (IP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ================================== CREATE DATAFRAME OF ALL PITCHER INFORMATION =====================================\n",
    "\n",
    "# empty list to append to for each year of information\n",
    "pitchersDF = []\n",
    "# loop through years of interest\n",
    "for year in year_list:\n",
    "    # open the file PlayerData/2016Pitchers (or whatever year)\n",
    "    with open('CSV_files/PlayerData/'+str(year)+'Pitchers') as inFile:\n",
    "        # convert csv file to pandas DataFrame\n",
    "        DF2016 = pd.read_csv(inFile)\n",
    "        # create year column\n",
    "        DF2016[\"Year\"] = year\n",
    "        # append to master list\n",
    "        pitchersDF.append(DF2016)\n",
    "#concatenate master list into pandas DataFrame\n",
    "pitchersDF = pd.concat(pitchersDF)\n",
    "# remove all except columns of interest for our particular project (files have more stats than we are interested in)\n",
    "pitchersDF = pitchersDF[[\"Name\", \"Age\", \"Tm\", \"Year\", \"SO\", \"W\", \"SV\", \"ERA\", \"WHIP\", \"IP\", \"H\", \"BB\", \"FIP\", \"BF\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the pitching data in a Pandas dataframe, we need to clean it. Right now, we have 5,625 rows and 9 columns in our pitchers dataframe. Before we get into the cleaning, here is a sample of what the pitchersDF looks like, and the null values that it contains at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Year</th>\n",
       "      <th>SO</th>\n",
       "      <th>W</th>\n",
       "      <th>SV</th>\n",
       "      <th>ERA</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>IP</th>\n",
       "      <th>H</th>\n",
       "      <th>BB</th>\n",
       "      <th>FIP</th>\n",
       "      <th>BF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fernando Abad*\\abadfe01</td>\n",
       "      <td>30</td>\n",
       "      <td>TOT</td>\n",
       "      <td>2016</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.329</td>\n",
       "      <td>46.2</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>3.98</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fernando Abad*\\abadfe01</td>\n",
       "      <td>30</td>\n",
       "      <td>MIN</td>\n",
       "      <td>2016</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.206</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>3.44</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fernando Abad*\\abadfe01</td>\n",
       "      <td>30</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.39</td>\n",
       "      <td>1.658</td>\n",
       "      <td>12.2</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>5.44</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.J. Achter\\achteaj01</td>\n",
       "      <td>27</td>\n",
       "      <td>LAA</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.460</td>\n",
       "      <td>37.2</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>5.85</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austin Adams\\adamsau01</td>\n",
       "      <td>29</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2016</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.82</td>\n",
       "      <td>1.855</td>\n",
       "      <td>18.1</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>5.98</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name  Age   Tm  Year  SO  W  SV   ERA   WHIP    IP   H  \\\n",
       "0  Fernando Abad*\\abadfe01   30  TOT  2016  41  1   1  3.66  1.329  46.2  40   \n",
       "1  Fernando Abad*\\abadfe01   30  MIN  2016  29  1   1  2.65  1.206  34.0  27   \n",
       "2  Fernando Abad*\\abadfe01   30  BOS  2016  12  0   0  6.39  1.658  12.2  13   \n",
       "3    A.J. Achter\\achteaj01   27  LAA  2016  14  1   0  3.11  1.460  37.2  43   \n",
       "4   Austin Adams\\adamsau01   29  CLE  2016  17  0   0  9.82  1.855  18.1  27   \n",
       "\n",
       "   BB   FIP   BF  \n",
       "0  22  3.98  198  \n",
       "1  14  3.44  138  \n",
       "2   8  5.44   60  \n",
       "3  12  5.85  160  \n",
       "4   7  5.98   88  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitchersDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name    0\n",
      "Age     0\n",
      "Tm      0\n",
      "Year    0\n",
      "SO      0\n",
      "W       0\n",
      "SV      0\n",
      "ERA     2\n",
      "WHIP    6\n",
      "IP      0\n",
      "H       0\n",
      "BB      0\n",
      "FIP     6\n",
      "BF      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print pitchersDF.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have several of the same issues as we saw above in the hitters dataframe. We will make all names lowercase, fix their formatting, and add a column for first initial and last name only. We again drop rows representing trades and keep only player totals across any given season. We will address these issues in the code that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace names with corrected version by removing the unnecessary portions that appear in the DF above\n",
    "pitchersDF['Name'] = pitchersDF['Name'].str.replace(r'[*|\\\\|#|\\+].*', '')\n",
    "# convert all names to lower case\n",
    "pitchersDF['Name'] = pitchersDF['Name'].apply(lower_names)\n",
    "# create columns separating out pieces of player names\n",
    "pitchersDF['First'], pitchersDF['First_initial'], pitchersDF['Last'] = \\\n",
    "        pitchersDF['Name'].apply(split_names_first),pitchersDF['Name'].apply(split_names_first_initial),\\\n",
    "        pitchersDF['Name'].apply(split_names_last)\n",
    "pitchersDF['Abbr_Name'] = pitchersDF['First_initial'] + ' ' + pitchersDF['Last']\n",
    "del pitchersDF['First'], pitchersDF['First_initial'], pitchersDF['Last']\n",
    "\n",
    "# drop duplicates - default is to keep first occurence\n",
    "for yr in year_list:\n",
    "    pitchersDF[pitchersDF[\"Year\"] == yr] = pitchersDF[pitchersDF[\"Year\"] == yr].drop_duplicates('Name')\n",
    "# drop rows with null values in the Name column\n",
    "pitchersDF = pitchersDF.dropna(subset = [\"Name\"], axis=0)\n",
    "# drop Team column\n",
    "pitchersDF = pitchersDF.drop(\"Tm\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had a few missing data points in the pitchers dataframe. In every case, the pitchers for which this occurred had no statistics for the given season. Thus, we dropped those pitchers from the dataframe for the respective years, especially because this only occured for 6 observations out of about 5,600. Lastly, we drop pitchers with fewer than 25 innings pitched in a given season, as these are not going to be significant players in the given season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop rows where pitcher had no stats recorded for the year\n",
    "pitchersDF = pitchersDF[pitchersDF.ERA.notnull()]\n",
    "pitchersDF = pitchersDF[pitchersDF.WHIP.notnull()]\n",
    "# Drop pitchers with fewer than 25 innings pitched in a given season\n",
    "pitchersDF = pitchersDF[pitchersDF[\"IP\"] > 25]\n",
    "# Reset the index values\n",
    "pitchersDF = pitchersDF.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign columns to the correct datatypes\n",
    "pitchersDF[\"Name\"] = pitchersDF[\"Name\"].astype(str)\n",
    "pitchersDF[\"Year\"] = pitchersDF[\"Year\"].astype(int)\n",
    "pitchersDF[\"SO\"] = pitchersDF[\"SO\"].astype(int)\n",
    "pitchersDF[\"W\"] = pitchersDF[\"W\"].astype(int)\n",
    "pitchersDF[\"SV\"] = pitchersDF[\"SV\"].astype(int)\n",
    "pitchersDF[\"Abbr_Name\"] = pitchersDF[\"Abbr_Name\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of these corrections, our pitchers dataframe is ready to use. We now have 3,157 rows and 8 columns. Here is a cleaned sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Year</th>\n",
       "      <th>SO</th>\n",
       "      <th>W</th>\n",
       "      <th>SV</th>\n",
       "      <th>ERA</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>IP</th>\n",
       "      <th>H</th>\n",
       "      <th>BB</th>\n",
       "      <th>FIP</th>\n",
       "      <th>BF</th>\n",
       "      <th>Abbr_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fernando abad</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.329</td>\n",
       "      <td>46.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.98</td>\n",
       "      <td>198.0</td>\n",
       "      <td>f. abad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a.j. achter</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.460</td>\n",
       "      <td>37.2</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.85</td>\n",
       "      <td>160.0</td>\n",
       "      <td>a. achter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tim adleman</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.206</td>\n",
       "      <td>69.2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>287.0</td>\n",
       "      <td>t. adleman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>matt albers</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.31</td>\n",
       "      <td>1.675</td>\n",
       "      <td>51.1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>237.0</td>\n",
       "      <td>m. albers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cody allen</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.31</td>\n",
       "      <td>264.0</td>\n",
       "      <td>c. allen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name   Age  Year  SO  W  SV   ERA   WHIP    IP     H    BB   FIP  \\\n",
       "0  fernando abad  30.0  2016  41  1   1  3.66  1.329  46.2  40.0  22.0  3.98   \n",
       "1    a.j. achter  27.0  2016  14  1   0  3.11  1.460  37.2  43.0  12.0  5.85   \n",
       "2    tim adleman  28.0  2016  47  4   0  4.00  1.206  69.2  64.0  20.0  5.30   \n",
       "3    matt albers  33.0  2016  30  2   0  6.31  1.675  51.1  67.0  19.0  5.80   \n",
       "4     cody allen  27.0  2016  87  3  32  2.51  1.000  68.0  41.0  27.0  3.31   \n",
       "\n",
       "      BF   Abbr_Name  \n",
       "0  198.0     f. abad  \n",
       "1  160.0   a. achter  \n",
       "2  287.0  t. adleman  \n",
       "3  237.0   m. albers  \n",
       "4  264.0    c. allen  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitchersDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table of some basic summary statistics for the dataset of actual pitcher statistics as well. It can be seen from the summary statistics that nothing seems out of range, and the values reported make sense given the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Year</th>\n",
       "      <th>SO</th>\n",
       "      <th>W</th>\n",
       "      <th>SV</th>\n",
       "      <th>ERA</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>IP</th>\n",
       "      <th>H</th>\n",
       "      <th>BB</th>\n",
       "      <th>FIP</th>\n",
       "      <th>BF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3607.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.252564</td>\n",
       "      <td>2012.553368</td>\n",
       "      <td>75.792903</td>\n",
       "      <td>5.204879</td>\n",
       "      <td>2.727474</td>\n",
       "      <td>3.995761</td>\n",
       "      <td>1.326870</td>\n",
       "      <td>90.604464</td>\n",
       "      <td>87.655670</td>\n",
       "      <td>30.487386</td>\n",
       "      <td>4.017444</td>\n",
       "      <td>384.876074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.104058</td>\n",
       "      <td>2.297571</td>\n",
       "      <td>51.230825</td>\n",
       "      <td>4.437449</td>\n",
       "      <td>8.327682</td>\n",
       "      <td>1.324327</td>\n",
       "      <td>0.229476</td>\n",
       "      <td>58.628642</td>\n",
       "      <td>58.182512</td>\n",
       "      <td>18.695380</td>\n",
       "      <td>0.968475</td>\n",
       "      <td>244.190186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>1.176500</td>\n",
       "      <td>47.200000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.370000</td>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>1.315000</td>\n",
       "      <td>66.200000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.463000</td>\n",
       "      <td>130.200000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.690000</td>\n",
       "      <td>2.374000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>9.230000</td>\n",
       "      <td>1009.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age         Year           SO            W           SV  \\\n",
       "count  3607.000000  3607.000000  3607.000000  3607.000000  3607.000000   \n",
       "mean     28.252564  2012.553368    75.792903     5.204879     2.727474   \n",
       "std       4.104058     2.297571    51.230825     4.437449     8.327682   \n",
       "min      19.000000  2009.000000     7.000000     0.000000     0.000000   \n",
       "25%      25.000000  2011.000000    38.000000     2.000000     0.000000   \n",
       "50%      27.000000  2013.000000    59.000000     4.000000     0.000000   \n",
       "75%      31.000000  2015.000000   101.000000     7.000000     1.000000   \n",
       "max      49.000000  2016.000000   301.000000    24.000000    51.000000   \n",
       "\n",
       "               ERA         WHIP           IP            H           BB  \\\n",
       "count  3607.000000  3607.000000  3607.000000  3607.000000  3607.000000   \n",
       "mean      3.995761     1.326870    90.604464    87.655670    30.487386   \n",
       "std       1.324327     0.229476    58.628642    58.182512    18.695380   \n",
       "min       0.450000     0.565000    25.100000    11.000000     2.000000   \n",
       "25%       3.090000     1.176500    47.200000    44.000000    17.000000   \n",
       "50%       3.860000     1.315000    66.200000    62.000000    25.000000   \n",
       "75%       4.750000     1.463000   130.200000   131.000000    41.000000   \n",
       "max      10.690000     2.374000   251.000000   262.000000   105.000000   \n",
       "\n",
       "               FIP           BF  \n",
       "count  3607.000000  3607.000000  \n",
       "mean      4.017444   384.876074  \n",
       "std       0.968475   244.190186  \n",
       "min       0.780000    90.000000  \n",
       "25%       3.370000   205.000000  \n",
       "50%       3.970000   279.000000  \n",
       "75%       4.620000   561.000000  \n",
       "max       9.230000  1009.000000  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitchersDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown below, we now have a nice clean pitchers dataset, free of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name         0\n",
      "Age          0\n",
      "Year         0\n",
      "SO           0\n",
      "W            0\n",
      "SV           0\n",
      "ERA          0\n",
      "WHIP         0\n",
      "IP           0\n",
      "H            0\n",
      "BB           0\n",
      "FIP          0\n",
      "BF           0\n",
      "Abbr_Name    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print pitchersDF.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Projection Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will scrape statistical projections for each of the seasons 2010-2015 from FanGraphs, Steamer, Guru, Marcel, CBS, and ESPN. We follow the same pattern for all 6 of the prediction methods. So, rather than printing out an example of each dataframe, its size, its null values, etc., we will give the summary of each dataframe here and explain any issues that arose. Then, we will go through the cleaning process for the Marcel dataframe in detail, which outlines the process we followed for the other 5 prediction methods. The rest will simply follow in code.\n",
    "\n",
    "- Marcel: \n",
    "    - This dataset was the hardest to clean. The dataset had a lot of features that are irrelevant to our problem, but this dataset was also missing two integral features: AVG and WHIP. We were able to engineer these features from the other features provided from this dataset. \n",
    "    - The pitchers dataframe was missing Saves for about 350 rows of the 2,000 rows of data. \n",
    "    - After cleaning, the hitters dataframe has about 1,800 rows and the pitchers has about 2,300 rows, which is 300/year and 380/year, respectively.\n",
    "- Fangraphs:\n",
    "    - Fangraphs did not predict saves for 2010 and 2011.\n",
    "    - After cleaning, the pitchers dataframe has about 1,500 rows and the hitters dataframe has about 1,200 rows. \n",
    "- Steamer:\n",
    "    - Steamer was the largest dataset at the outset. This is because it predicted statistics for every possible player. \n",
    "    - Steamer did not predict Saves.\n",
    "    - After cleaning, the hitters dataframe has about 1,900 rows and the pitchers dataframe has about 2,500 rows.\n",
    "- Guru:\n",
    "    - For non-closers, the Guru data had \"-\" for saves instead of 0's. So, we replaced those.\n",
    "    - Guru had about 300 rows of missing data. However, on inspection of these players we found that these players are minimal playing time players and bench players, thus they will not be important for fantasy baseball as only the top 300-400 players are drafted. So, we dropped those players and were left with no missing values.\n",
    "    - After cleaning, the hitters dataframe has about 1,600 rows and the pitchers dataframe has about 2,300 rows.\n",
    "- ESPN: \n",
    "    - ESPN is missing Saves for 1 year.\n",
    "    - ESPN, like Guru, included some players of minor importance and instead of being Nan values they had \"--\". We treated this like Nan values and again dropped them because they are not of importance for fantasy baseball purposes. \n",
    "    - After cleaning, the hitters dataframe has about 1,800 rows and the pitchers dataframe has about 1,800 rows.\n",
    "- CBS:\n",
    "    - CBS is missing Runs for 1 year.\n",
    "    - After cleaning, the hitters dataframe has about 1,800 rows and the pitchers dataframe has about 1,800 rows.\n",
    "\n",
    "As mentioned above, a few of the projection methods did not predict Saves or are missing Saves for a season or two. This will not be a serious issue for us, as we plan to run models on each statistic seperately. So, in the case of Steamer (no Saves predictions), we simply won't include this method when we try to determine who the best is at predicting Saves. As for the methods that are missing Saves for a couple of seasons, or CBS is missing runs for a season, this will not be a showstopper. There is no way to engineer these values as they are created from a specific model that we do not have access to, doing so would skew our data greatly, and in the case of Saves they are completely independent of the other statistics. So, we won't include that year when analyzing that particular statistic, i.e. Fangraphs is missing saves for 2010, so we won't include Fangraphs 2010 when measuring Fangraphs ability to predict saves. We do not drop these years or rows entirely as they still contain the predictions of the other statistics and provide extreme value. \n",
    "\n",
    "Another note about the data is the size of our dataframes. While we would ideally like to have more datapoints, prediction data is hard to obtain. Plus, most predictions are only concerned with the top 300 players, so for 6 years that is only 1,800 rows of data. We were able to obtain predictions for the years 2010-2015, which results in about 1,400-2,100 rows of data for each dataframe. These are not as large as we like, but we will still move forward. In addition, we were unable to acquire projections for 2016. This data was not available anywhere. While unfortunate, this does not restrict our methods or models we plan on using, but it is important to note. We have not obtained the 2017 predictions yet as they have not all been published, because spring training is currently happening and that affects some of the prediction methods. We will obtain this data in a couple of weeks when spring training is completed and the predictions are completed. Also, while we are watching for these to appear, we will keep an eye open for the 2016 data.\n",
    "\n",
    "While our dataset is smaller than what is ideal, and we do not have 2016 projections, we can be sure that this data is very reliable. First off, our official statistics dataframes come from baseball-reference.com, which is the leading site in baseball statistics. Every baseball site, blog, and analyst including the leaders such as ESPN, CBS sports, Fox Sports, etc. use baseball-reference.com. The actual projections come from the various websites and many articles on Bleacher Report, Razzball, Fantasy Pros, etc. reference these different projection methods. So, we assume that these are reliable data. A potential bias could occur, if, say ESPN went back and changed their projections for previous years to appear more accurate. However, we believe this will not be an issue as we obtained the data from a 3rd party that does not have immediate ties to any of the 6 projection methods. This 3rd party is reliable as it is referenced in many articles from the leading sports pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list for looping through seasons in cleaning\n",
    "season = np.arange(2010,2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realized that we did not have need for predictions for every single player in the MLB because our league will only draft a given number of players.  As such, we chose to use the hitters and pitchers with at bats and pitches above a given threshold.  Using this list of players for every given year we created a mask and selected these players from each of our 6 sites.  Due to naming conventions we had to use an extra function to check matching names on both a complete name basis as well as using a first initial and last name on the subset of names leftover from the first check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename the statistics in the hittersDF so we can differentiate the actual and predicted statistics when we merge\n",
    "hittersDF = hittersDF.rename(columns = {'Year':'Season', 'R' : 'actual_R', 'HR' : \"actual_HR\", \\\n",
    "                                        'RBI': 'actual_RBI', 'SB': 'actual_SB', 'BA': 'actual_AVG', 'AB':'actual_AB',\\\n",
    "                                       '2B': 'actual_2B', '3B': 'actual_3B', 'Age': 'actual_age', 'BB': 'actual_BB',\\\n",
    "                                       'OBP': 'actual_OBP', 'SLG': 'actual_SLG', 'SO': 'actual_SO'})\n",
    "\n",
    "#Rename the statistics in the pitchersDF so we can differentiate the actual and predicted statistics when we merge\n",
    "pitchersDF = pitchersDF.rename(columns = {'Year':'Season', 'SO' : 'actual_K', 'W' : \"actual_W\", 'ERA': 'actual_ERA',\\\n",
    "                                          'WHIP': 'actual_WHIP', 'IP': 'actual_IP', 'SV':'actual_SV', \\\n",
    "                                          'FIP':'actual_FIP', 'BB': 'actual_BB', 'BF': 'actual_BF', 'H': 'actual_H'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_names(df, site_df, season=season):\n",
    "    \n",
    "    # we create blank data frames that we will be using to store the necessary data, we might need to work on naming\n",
    "    #     conventions...\n",
    "    \n",
    "    # dataframe containing Name hits from both the site DFs and the PlayerData DFs\n",
    "    new_site_df_1 = pd.DataFrame()\n",
    "    \n",
    "    # dataframe containing Name hits NOT IN PlayerData DF\n",
    "    not_site_df_1 = pd.DataFrame()\n",
    "    \n",
    "    # dataframe containing names in PlayerData DF and not the site DF\n",
    "    allyson_not = pd.DataFrame()\n",
    "    \n",
    "    # Observe these next three dataframes are to see the same information as before but for Abbr_Name and within the\n",
    "    #     intersection of the previous dataframes\n",
    "    new_site_df_2 = pd.DataFrame()\n",
    "    not_site_df_2 = pd.DataFrame()\n",
    "    allyson_not_site = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    # loop through every season.  Observe a couple sites are missing data for different seasons which is why we allow\n",
    "    #     the user to pass in the appropriate seasons they wish to use.\n",
    "    for i in season:\n",
    "        \n",
    "        # checking for names that exist in both pitchersDF and espn_pitchers\n",
    "        dfcheck = df[df['Season']==i]\n",
    "        site_df_check = site_df[site_df['Season']==i]\n",
    "\n",
    "        # we were using more complex 'isin' checks but opted to just use a pd.merge because we eventually needed to \n",
    "        #     combine the site data with the actual player DF, same applies to code below\n",
    "        df_subset_1_TEST = pd.merge(site_df_check, dfcheck, on=['Name', 'Season'])\n",
    "        new_site_df_1 = new_site_df_1.append(df_subset_1_TEST)\n",
    "        ####df_subset_1 = site_df[(site_df['Name'].isin(dfcheck['Name'])) & (site_df['Season']==i)]\n",
    "        ####new_site_df_1 = new_site_df_1.append(df_subset_1)        \n",
    "        \n",
    "        not_df_subset_1 = site_df[(site_df['Name'].isin(dfcheck['Name'])==False) & (site_df['Season']==i)]\n",
    "        not_site_df_1 = not_site_df_1.append(not_df_subset_1)\n",
    "\n",
    "        not_allyson_subset = df[(df['Name'].isin(site_df_check['Name'])==False)& (df['Season']==i)]\n",
    "        allyson_not = allyson_not.append(not_allyson_subset)\n",
    "\n",
    "        # checking for names that did not exist in both pitchersDF and source, but do match first initials\n",
    "        allysoncheck = allyson_not[allyson_not['Season']==i]\n",
    "        sitecheck = not_site_df_1[not_site_df_1['Season']==i]\n",
    "\n",
    "        site_df_subset_TEST = pd.merge(not_site_df_1, allysoncheck, on=['Abbr_Name', 'Season'])\n",
    "        new_site_df_2 = new_site_df_2.append(site_df_subset_TEST)\n",
    "        ####site_df_subset = not_site_df_1[(not_site_df_1['Abbr_Name'].isin(allysoncheck['Abbr_Name'])) & \\\n",
    "        ####                               (not_site_df_1['Season']==i)]\n",
    "        ####new_site_df_2 = new_site_df_2.append(site_df_subset)\n",
    "\n",
    "        not_df_subset_2 = not_site_df_1[(not_site_df_1['Abbr_Name'].isin(allysoncheck['Abbr_Name'])==False) & \\\n",
    "                                        (not_site_df_1['Season']==i)]\n",
    "        not_site_df_2 = not_site_df_2.append(not_df_subset_2)\n",
    "\n",
    "        not_allyson_subset_2 = allyson_not[(allyson_not['Abbr_Name'].isin(sitecheck['Abbr_Name'])==False)& \\\n",
    "                                           (allyson_not['Season']==i)]\n",
    "        allyson_not_site = allyson_not_site.append(not_allyson_subset_2)\n",
    "\n",
    "        \n",
    "    # observe that because we did not merge on all columns with a common name we ended up with several columns\n",
    "    #     with a naming convention such as '_y' so we use some regex to clean these up for applicable dataframes\n",
    "    \n",
    "    for col in new_site_df_1.columns:\n",
    "        if '_x' in col:\n",
    "            new_site_df_1[col[:-2]] = new_site_df_1[col]\n",
    "    for col in new_site_df_2.columns:\n",
    "        if '_x' in col:\n",
    "            new_site_df_2[col[:-2]] = new_site_df_2[col]\n",
    "    \n",
    "    new_site_df_1 = new_site_df_1.select(lambda x: not re.search(r'.*\\_y', x), axis=1)\n",
    "    new_site_df_2 = new_site_df_2.select(lambda x: not re.search(r'.*\\_y', x), axis=1)\n",
    "    \n",
    "    new_site_df_1 = new_site_df_1.select(lambda x: not re.search(r'.*\\_x', x), axis=1)\n",
    "    new_site_df_2 = new_site_df_2.select(lambda x: not re.search(r'.*\\_x', x), axis=1)\n",
    "    \n",
    "    # observe we are returning 6 components but only use 2 for our final dataframes.  The reason for these extra \n",
    "    #     dataframes was for checking to ensure our function was properly working\n",
    "    return new_site_df_1, not_site_df_1, allyson_not, new_site_df_2, not_site_df_2, allyson_not_site\n",
    "\n",
    "#### signifies code we are not currently using but might need in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_names2(df, site_df, season=season):\n",
    "    site_df_replace = site_df.copy()\n",
    "    df['Prediction_Season'] = df['Season']+1\n",
    "    site_df_replace['Prediction_Season'] = site_df['Season']\n",
    "    \n",
    "    for col in site_df_replace.columns:\n",
    "        if 'actual_' in col:\n",
    "            del site_df_replace[col]\n",
    "    \n",
    "    # this is the the same as find_names but is combining the current year's predictions with the previous year's \n",
    "    #     actual statistics\n",
    "    \n",
    "    #print df[df['Abbr_Name']=='a. pujols'][['Abbr_Name', 'actual_HR', 'Prediction_Season']]\n",
    "    \n",
    "    # we create blank data frames that we will be using to store the necessary data, we might need to work on naming\n",
    "    #     conventions...\n",
    "    \n",
    "    # dataframe containing Name hits from both the site DFs and the PlayerData DFs\n",
    "    new_site_df_1 = pd.DataFrame()\n",
    "    new_site_df_new_stats_1 = pd.DataFrame()\n",
    "    \n",
    "    # dataframe containing Name hits NOT IN PlayerData DF\n",
    "    not_site_df_1 = pd.DataFrame()\n",
    "    \n",
    "    # dataframe containing names in PlayerData DF and not the site DF\n",
    "    allyson_not = pd.DataFrame()\n",
    "    \n",
    "    # Observe these next three dataframes are to see the same information as before but for Abbr_Name and within the\n",
    "    #     intersection of the previous dataframes\n",
    "    new_site_df_2 = pd.DataFrame()\n",
    "    \n",
    "    new_site_df_new_stats_2 = pd.DataFrame()\n",
    "    \n",
    "    not_site_df_2 = pd.DataFrame()\n",
    "    allyson_not_site = pd.DataFrame()\n",
    "\n",
    "    \n",
    "    # loop through every season.  Observe a couple sites are missing data for different seasons which is why we allow\n",
    "    #     the user to pass in the appropriate seasons they wish to use.\n",
    "    for i in season:\n",
    "        \n",
    "        # checking for names that exist in both pitchersDF and espn_pitchers\n",
    "        dfcheck = df[df['Prediction_Season']==i]\n",
    "        site_df_check = site_df_replace[site_df_replace['Prediction_Season']==i]\n",
    "        \n",
    "        #dfcheck_new_stats = df[df['Season']==i-1]\n",
    "        #site_df_check_new_stats = site_df[site_df['Season']==i]\n",
    "\n",
    "        # we were using more complex 'isin' checks but opted to just use a pd.merge because we eventually needed to \n",
    "        #     combine the site data with the actual player DF, same applies to code below\n",
    "        df_subset_1_TEST = pd.merge(site_df_check, dfcheck, on=['Name', 'Prediction_Season'])\n",
    "        new_site_df_1 = new_site_df_1.append(df_subset_1_TEST)\n",
    "        \n",
    "        #df_subset_1_TEST_new_stats = pd.merge(site_df_check, dfcheck_new_stats, on=['Name', 'Prediction_season'])\n",
    "        #new_site_df_new_stats_1 = new_site_df_new_stats_1.append(df_subset_1_TEST_new_stats)\n",
    "        ####df_subset_1 = site_df[(site_df['Name'].isin(dfcheck['Name'])) & (site_df['Season']==i)]\n",
    "        ####new_site_df_1 = new_site_df_1.append(df_subset_1)        \n",
    "        \n",
    "        not_df_subset_1 = site_df_replace[(site_df_replace['Name'].isin(dfcheck['Name'])==False) & (site_df_replace['Prediction_Season']==i)]\n",
    "        not_site_df_1 = not_site_df_1.append(not_df_subset_1)\n",
    "\n",
    "        not_allyson_subset = df[(df['Name'].isin(site_df_check['Name'])==False) & (df['Prediction_Season']==i)]\n",
    "        allyson_not = allyson_not.append(not_allyson_subset)\n",
    "        \n",
    "        ####not_ally_subset_new = df[(df['Name'].isin(site_df_check_new_stats['Name'])==False) & df[]]\n",
    "        \n",
    "        \n",
    "        # checking for names that did not exist in both pitchersDF and source, but do match first initials\n",
    "        allysoncheck = allyson_not[allyson_not['Prediction_Season']==i]\n",
    "        sitecheck = not_site_df_1[not_site_df_1['Prediction_Season']==i]\n",
    "        \n",
    "\n",
    "        site_df_subset_TEST = pd.merge(not_site_df_1, allysoncheck, on=['Abbr_Name', 'Prediction_Season'])\n",
    "        new_site_df_2 = new_site_df_2.append(site_df_subset_TEST)\n",
    "        \n",
    "        #site_df_subset_TEST_new_stats = pd.merge(not_site_df_1, allysoncheck, on=['Abbr_Name', 'Prediction_season'])\n",
    "        #new_site_df_new_stats_2 = new_site_df_2.append(site_df_subset_TEST)\n",
    "        ####site_df_subset = not_site_df_1[(not_site_df_1['Abbr_Name'].isin(allysoncheck['Abbr_Name'])) & \\\n",
    "        ####                               (not_site_df_1['Season']==i)]\n",
    "        ####new_site_df_2 = new_site_df_2.append(site_df_subset)\n",
    "\n",
    "        not_df_subset_2 = not_site_df_1[(not_site_df_1['Abbr_Name'].isin(allysoncheck['Abbr_Name'])==False) & \\\n",
    "                                        (not_site_df_1['Prediction_Season']==i)]\n",
    "        not_site_df_2 = not_site_df_2.append(not_df_subset_2)\n",
    "\n",
    "        not_allyson_subset_2 = allyson_not[(allyson_not['Abbr_Name'].isin(sitecheck['Abbr_Name'])==False)& \\\n",
    "                                           (allyson_not['Prediction_Season']==i)]\n",
    "        allyson_not_site = allyson_not_site.append(not_allyson_subset_2)\n",
    "\n",
    "        \n",
    "    # observe that because we did not merge on all columns with a common name we ended up with several columns\n",
    "    #     with a naming convention such as '_y' so we use some regex to clean these up for applicable dataframes\n",
    "    \n",
    "    for col in new_site_df_1.columns:\n",
    "        if '_x' in col:\n",
    "            new_site_df_1[col[:-2]] = new_site_df_1[col]\n",
    "    for col in new_site_df_2.columns:\n",
    "        if '_x' in col:\n",
    "            new_site_df_2[col[:-2]] = new_site_df_2[col]\n",
    "\n",
    "    new_site_df_1 = new_site_df_1.select(lambda x: not re.search(r'.*\\_y', x), axis=1)\n",
    "    new_site_df_1 = new_site_df_1.select(lambda x: not re.search(r'.*\\_x', x), axis=1)\n",
    "    \n",
    "    new_site_df_2 = new_site_df_2.select(lambda x: not re.search(r'.*\\_y', x), axis=1)\n",
    "    new_site_df_2 = new_site_df_2.select(lambda x: not re.search(r'.*\\_x', x), axis=1)\n",
    "    \n",
    "    for col in new_site_df_1.columns:\n",
    "        if 'actual_' in col:\n",
    "            new_site_df_1 = new_site_df_1.rename(columns={col:'previous_'+col[7:]})\n",
    "    for col in new_site_df_2.columns:\n",
    "        if 'actual_' in col:\n",
    "            new_site_df_2 = new_site_df_2.rename(columns={col:'previous_'+col[7:]})\n",
    "    \n",
    "    # observe we are returning 6 components but only use 2 for our final dataframes.  The reason for these extra \n",
    "    #     dataframes was for checking to ensure our function was properly working\n",
    "    return new_site_df_1, not_site_df_1, allyson_not, new_site_df_2, not_site_df_2, allyson_not_site\n",
    "\n",
    "#### signifies code we are not currently using but might need in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_correct_column(df,statistics):\n",
    "    \"\"\"This function adds columns to our dataframes that classify whether a prediction is correct or not. We pass\n",
    "    in a dataframe and a dictionary of statistics, where the keys are stats and the values are the epsilon balls.\n",
    "    Then we make a column and add the value 1 if the projection for a statistic is within the epsilon ball of the \n",
    "    actual stat and a 0 if it is outside the epsilon ball.\n",
    "    Parameters\n",
    "    df: dataframe we want to adjust\n",
    "    statistic: dict where keys are stats and values are epsilon ball values\n",
    "    returns: Nothing, but it adds columns to the dataframe that are binary with 1's = a correct prediction\"\"\"\n",
    "    for i in statistics:\n",
    "        difference = statistics.get(i)\n",
    "        df['correct_'+i] = ((df['actual_'+i]<df[i]+difference)&(df['actual_'+i]>df[i]-difference)).astype('int')\n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now detail the process of cleaning the Marcel data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marcel\n",
    "Marcel is a baseball statistic projection system that claims to be very basic in its methods. It uses the past 3 years to predict each current year, weighting recent data more heavily. We now read in the Marcel data and put it into pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marcel_pitchers_2013.csv\n",
      "marcel_pitchers_2014.csv\n",
      "marcel_pitchers_2015.csv\n",
      "marcel_pitchers_2010.csv\n",
      "marcel_pitchers_2012.csv\n",
      "marcel_pitchers_2011.csv\n",
      "marcel hitters (6792, 26)\n",
      "marcel pitchers (5716, 28)\n"
     ]
    }
   ],
   "source": [
    "# ============================ CREATE DATAFRAMES OF MARCEL PITCHER & HITTER PROJECTIONS ===============================\n",
    "\n",
    "# empty lists to append to for each year of information\n",
    "marcel_hitters = []\n",
    "marcel_pitchers = []\n",
    "\n",
    "# append to pitchers dataframe\n",
    "for ID in os.listdir('CSV_files/marcel_pitchers/'):\n",
    "    print ID\n",
    "    if ID not in '.listing':\n",
    "        with open(os.path.join('./CSV_files/marcel_pitchers/', ID)) as inFile:\n",
    "            marcel_pitchers.append(pd.read_csv(inFile))\n",
    "            \n",
    "# append to hitters dataframe\n",
    "for ID in os.listdir('CSV_files/marcel_hitters/'):\n",
    "    if ID not in '.listing':\n",
    "        with open(os.path.join('./CSV_files/marcel_hitters/', ID)) as inFile:\n",
    "            marcel_hitters.append(pd.read_csv(inFile))\n",
    "\n",
    "# concatenate master lists into dataframes\n",
    "marcel_hitters = pd.concat(marcel_hitters)\n",
    "marcel_pitchers = pd.concat(marcel_pitchers)\n",
    "\n",
    "# check the sizes of our dataframes\n",
    "print \"marcel hitters\", marcel_hitters.shape\n",
    "print \"marcel pitchers\", marcel_pitchers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the Marcel projection data in two Pandas dataframes, we need to clean them. Right now, we have 6,158 rows and 27 columns in our hitters dataframe and we have 5,716 rows and 29 columns in our pitchers dataframe.\n",
    "Before we get into the cleaning, here is a sample of what the Marcel hitters dataframe looks like, and its null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AVG</th>\n",
       "      <th>Age</th>\n",
       "      <th>HR</th>\n",
       "      <th>Name</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>Season</th>\n",
       "      <th>m2B</th>\n",
       "      <th>...</th>\n",
       "      <th>mIBB</th>\n",
       "      <th>mPA</th>\n",
       "      <th>mSF</th>\n",
       "      <th>mSH</th>\n",
       "      <th>mSO</th>\n",
       "      <th>nameFirst</th>\n",
       "      <th>nameLast</th>\n",
       "      <th>playerID</th>\n",
       "      <th>reliability</th>\n",
       "      <th>wOBA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180</td>\n",
       "      <td>0.261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>Brent Clevlen</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216</td>\n",
       "      <td>0.245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>Steven Tolleson</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190</td>\n",
       "      <td>0.258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Andrew Romine</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>0.234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Lou Marson</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181</td>\n",
       "      <td>0.254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>Joe Thurston</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AB    AVG  Age  HR             Name   R  RBI  SB  Season  m2B  ...   mIBB  \\\n",
       "0  180  0.261  NaN   6    Brent Clevlen  24   22   4    2013  NaN  ...    NaN   \n",
       "1  216  0.245  NaN   7  Steven Tolleson  24   24   4    2013  NaN  ...    NaN   \n",
       "2  190  0.258  NaN   5    Andrew Romine  24   21   5    2013  NaN  ...    NaN   \n",
       "3  303  0.234  NaN   4       Lou Marson  38   28   7    2013  NaN  ...    NaN   \n",
       "4  181  0.254  NaN   6     Joe Thurston  23   22   4    2013  NaN  ...    NaN   \n",
       "\n",
       "   mPA  mSF  mSH  mSO  nameFirst  nameLast  playerID  reliability  wOBA  \n",
       "0  NaN  NaN  NaN  NaN        NaN       NaN       NaN          NaN   NaN  \n",
       "1  NaN  NaN  NaN  NaN        NaN       NaN       NaN          NaN   NaN  \n",
       "2  NaN  NaN  NaN  NaN        NaN       NaN       NaN          NaN   NaN  \n",
       "3  NaN  NaN  NaN  NaN        NaN       NaN       NaN          NaN   NaN  \n",
       "4  NaN  NaN  NaN  NaN        NaN       NaN       NaN          NaN   NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marcel_hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB                0\n",
      "AVG            2560\n",
      "Age            4232\n",
      "HR                0\n",
      "Name           2560\n",
      "R                 0\n",
      "RBI               0\n",
      "SB                0\n",
      "Season            0\n",
      "m2B            4232\n",
      "m3B            4232\n",
      "mBB            4232\n",
      "mCS            4232\n",
      "mGIDP          4232\n",
      "mH             4232\n",
      "mHBP           4232\n",
      "mIBB           4232\n",
      "mPA            4232\n",
      "mSF            4232\n",
      "mSH            4232\n",
      "mSO            4232\n",
      "nameFirst      4232\n",
      "nameLast       4232\n",
      "playerID       4232\n",
      "reliability    4232\n",
      "wOBA           4232\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print marcel_hitters.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample of the Marcel pitcher data, and its null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ERA</th>\n",
       "      <th>IP</th>\n",
       "      <th>K</th>\n",
       "      <th>Name</th>\n",
       "      <th>SV</th>\n",
       "      <th>Season</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>bsrER</th>\n",
       "      <th>...</th>\n",
       "      <th>mHR</th>\n",
       "      <th>mIBB</th>\n",
       "      <th>mL</th>\n",
       "      <th>mR</th>\n",
       "      <th>mRepl</th>\n",
       "      <th>mWP</th>\n",
       "      <th>nameFirst</th>\n",
       "      <th>nameLast</th>\n",
       "      <th>playerID</th>\n",
       "      <th>reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.32</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Sean Gallagher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.74</td>\n",
       "      <td>38.0</td>\n",
       "      <td>34</td>\n",
       "      <td>Yoshinori Tateyama</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.15</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Danny Herrera</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.346154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.72</td>\n",
       "      <td>58.0</td>\n",
       "      <td>50</td>\n",
       "      <td>Jose Mijares</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1.362069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.29</td>\n",
       "      <td>161.7</td>\n",
       "      <td>137</td>\n",
       "      <td>Philip Hughes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>13</td>\n",
       "      <td>1.280148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   ERA     IP    K                Name   SV  Season   W      WHIP  \\\n",
       "0  NaN  4.32   25.0   21      Sean Gallagher  1.0    2013   1  1.360000   \n",
       "1  NaN  4.74   38.0   34  Yoshinori Tateyama  1.0    2013   2  1.315789   \n",
       "2  NaN  4.15   26.0   21       Danny Herrera  1.0    2013   1  1.346154   \n",
       "3  NaN  3.72   58.0   50        Jose Mijares  1.0    2013   3  1.362069   \n",
       "4  NaN  4.29  161.7  137       Philip Hughes  1.0    2013  13  1.280148   \n",
       "\n",
       "   bsrER     ...      mHR  mIBB  mL  mR  mRepl  mWP  nameFirst  nameLast  \\\n",
       "0    NaN     ...      NaN   NaN NaN NaN    NaN  NaN        NaN       NaN   \n",
       "1    NaN     ...      NaN   NaN NaN NaN    NaN  NaN        NaN       NaN   \n",
       "2    NaN     ...      NaN   NaN NaN NaN    NaN  NaN        NaN       NaN   \n",
       "3    NaN     ...      NaN   NaN NaN NaN    NaN  NaN        NaN       NaN   \n",
       "4    NaN     ...      NaN   NaN NaN NaN    NaN  NaN        NaN       NaN   \n",
       "\n",
       "   playerID  reliability  \n",
       "0       NaN          NaN  \n",
       "1       NaN          NaN  \n",
       "2       NaN          NaN  \n",
       "3       NaN          NaN  \n",
       "4       NaN          NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marcel_pitchers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age            2864\n",
      "ERA               0\n",
      "IP                0\n",
      "K                 0\n",
      "Name           2852\n",
      "SV              950\n",
      "Season            0\n",
      "W                 0\n",
      "WHIP           2852\n",
      "bsrER          2864\n",
      "lgID           2864\n",
      "mBB            2864\n",
      "mBK            2864\n",
      "mER            2864\n",
      "mG             3828\n",
      "mGS            3828\n",
      "mH             2864\n",
      "mHBP           2864\n",
      "mHR            2864\n",
      "mIBB           2864\n",
      "mL             2864\n",
      "mR             2864\n",
      "mRepl          4764\n",
      "mWP            2864\n",
      "nameFirst      2864\n",
      "nameLast       2864\n",
      "playerID       2864\n",
      "reliability    2864\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print marcel_pitchers.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now clean the Marcel data. First of all, this dataset is missing WHIP for pitchers and AVG for hitters, which we will derive from the other features that are available. We also create a Name column that includes both first and last names together, and make that all lower case. Secondly, the dataset as is contains much more information than we need, so we will drop all columns except those of particular interest to us. Thirdly, we change player names to all lowercase for the sake of uniformity within the dataset and among our other datasets, and create a column holding the first initial and last name of each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# engineering of WHIP and AVG, engineering of single name column\n",
    "marcel_pitchers['Name'] = np.where(marcel_pitchers['Name'].isnull(), \\\n",
    "                        marcel_pitchers['nameFirst'] + ' ' + marcel_pitchers['nameLast'], marcel_pitchers['Name'])\n",
    "marcel_pitchers['WHIP'] = np.where(marcel_pitchers['WHIP'].isnull(), \\\n",
    "                        (marcel_pitchers['mBB']+marcel_pitchers['mH'])/marcel_pitchers['IP'], marcel_pitchers['WHIP'])\n",
    "marcel_hitters['Name'] = np.where(marcel_hitters['Name'].isnull(), \\\n",
    "                        marcel_hitters['nameFirst'] + ' ' + marcel_hitters['nameLast'], marcel_hitters['Name'])\n",
    "marcel_hitters['AVG'] = np.where(marcel_hitters['AVG'].isnull(), \\\n",
    "                        (marcel_hitters['mH'])/marcel_hitters['AB'], marcel_hitters['AVG'])\n",
    "\n",
    "# keep only columns includings stats we care about\n",
    "marcel_pitchers = marcel_pitchers[['Name', 'K', 'W', 'IP', 'ERA', 'WHIP', 'Season']]\n",
    "marcel_pitchers.columns = ['Name', 'K', 'W', 'IP', 'ERA', 'WHIP', 'Season']\n",
    "marcel_hitters = marcel_hitters[['Name', 'AB', 'RBI', 'R','HR', 'SB', 'AVG', 'Season']]\n",
    "marcel_hitters.columns = ['Name', 'AB', 'RBI', 'R','HR', 'SB', 'AVG', 'Season']\n",
    "\n",
    "# convert names to all lower case letters for uniformity\n",
    "marcel_pitchers['Name'] = marcel_pitchers['Name'].apply(lower_names)\n",
    "marcel_hitters['Name'] = marcel_hitters['Name'].apply(lower_names)\n",
    "\n",
    "# create a column for first initial and last name for each player\n",
    "marcel_pitchers['First'], marcel_pitchers['First_initial'], marcel_pitchers['Last'] = \\\n",
    "        marcel_pitchers['Name'].apply(split_names_first),marcel_pitchers['Name'].apply(split_names_first_initial),\\\n",
    "        marcel_pitchers['Name'].apply(split_names_last)\n",
    "marcel_pitchers['Abbr_Name'] = marcel_pitchers['First_initial'] + ' ' + marcel_pitchers['Last']\n",
    "marcel_hitters['First'], marcel_hitters['First_initial'], marcel_hitters['Last'] = \\\n",
    "        marcel_hitters['Name'].apply(split_names_first),marcel_hitters['Name'].apply(split_names_first_initial),\\\n",
    "        marcel_hitters['Name'].apply(split_names_last)\n",
    "marcel_hitters['Abbr_Name'] = marcel_hitters['First_initial'] + ' ' + marcel_hitters['Last']\n",
    "\n",
    "# delete the extra columns we made to get the abbr_name column\n",
    "del marcel_hitters['First'], marcel_hitters['First_initial'], marcel_hitters['Last']\n",
    "del marcel_pitchers['First'], marcel_pitchers['First_initial'], marcel_pitchers['Last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign columns to the correct datatypes\n",
    "marcel_hitters[\"AB\"] = pd.to_numeric(marcel_hitters.AB)\n",
    "marcel_hitters[\"AB\"] = marcel_hitters[\"AB\"].astype(int)\n",
    "marcel_hitters[\"RBI\"] = marcel_hitters[\"RBI\"].astype(int)\n",
    "marcel_hitters[\"R\"] = marcel_hitters[\"R\"].astype(int)\n",
    "marcel_hitters[\"HR\"] = marcel_hitters[\"HR\"].astype(int)\n",
    "marcel_hitters[\"SB\"] = marcel_hitters[\"SB\"].astype(int)\n",
    "marcel_hitters[\"Season\"] = marcel_hitters[\"Season\"].astype(int)\n",
    "\n",
    "marcel_pitchers[\"K\"] = marcel_pitchers[\"K\"].astype(int)\n",
    "marcel_pitchers[\"W\"] = marcel_pitchers[\"W\"].astype(int)\n",
    "marcel_pitchers[\"Season\"] = marcel_pitchers[\"Season\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "marcel_hitters_2017 = marcel_hitters[marcel_hitters['Season']==2017]\n",
    "new_df_hit_predict = find_names2(hittersDF, marcel_hitters_2017, [2017])\n",
    "marcel_hitters_2017 = new_df_hit_predict[0].append(new_df_hit_predict[3])\n",
    "\n",
    "new_df_pitch = find_names(pitchersDF, marcel_pitchers, season)\n",
    "new_df_hit = find_names(hittersDF, marcel_hitters, season)\n",
    "\n",
    "marcel_pitchers = new_df_pitch[0].append(new_df_pitch[3])\n",
    "marcel_hitters = new_df_hit[0].append(new_df_hit[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the Marcel data is cleaned and ready to use. The pitchers dataframe is 2,354 rows and 8 columns and the hitters dataframe is 1,876 rows and 9 columns. Below are samples of each (hitters, then pitchers), which will show the cleaned dataframes and the fact that we have taken care of all null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AVG</th>\n",
       "      <th>Abbr_Name</th>\n",
       "      <th>HR</th>\n",
       "      <th>Name</th>\n",
       "      <th>Pos Summary</th>\n",
       "      <th>Prediction_Season</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>...</th>\n",
       "      <th>actual_AVG</th>\n",
       "      <th>actual_BB</th>\n",
       "      <th>actual_HR</th>\n",
       "      <th>actual_OBP</th>\n",
       "      <th>actual_R</th>\n",
       "      <th>actual_RBI</th>\n",
       "      <th>actual_SB</th>\n",
       "      <th>actual_SLG</th>\n",
       "      <th>actual_SO</th>\n",
       "      <th>actual_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>508</td>\n",
       "      <td>0.322835</td>\n",
       "      <td>a. pujols</td>\n",
       "      <td>34</td>\n",
       "      <td>albert pujols</td>\n",
       "      <td>*3</td>\n",
       "      <td>2011</td>\n",
       "      <td>96</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312</td>\n",
       "      <td>103.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.414</td>\n",
       "      <td>115</td>\n",
       "      <td>118</td>\n",
       "      <td>14</td>\n",
       "      <td>0.596</td>\n",
       "      <td>76.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>528</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>p. fielder</td>\n",
       "      <td>37</td>\n",
       "      <td>prince fielder</td>\n",
       "      <td>*3/D</td>\n",
       "      <td>2011</td>\n",
       "      <td>88</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261</td>\n",
       "      <td>114.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.401</td>\n",
       "      <td>94</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0.471</td>\n",
       "      <td>138.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>521</td>\n",
       "      <td>0.320537</td>\n",
       "      <td>h. ramirez</td>\n",
       "      <td>24</td>\n",
       "      <td>hanley ramirez</td>\n",
       "      <td>*6</td>\n",
       "      <td>2011</td>\n",
       "      <td>97</td>\n",
       "      <td>75</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.378</td>\n",
       "      <td>92</td>\n",
       "      <td>76</td>\n",
       "      <td>32</td>\n",
       "      <td>0.475</td>\n",
       "      <td>93.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>447</td>\n",
       "      <td>0.286353</td>\n",
       "      <td>a. rodriguez</td>\n",
       "      <td>31</td>\n",
       "      <td>alex rodriguez</td>\n",
       "      <td>*5D</td>\n",
       "      <td>2011</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270</td>\n",
       "      <td>59.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.341</td>\n",
       "      <td>74</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>0.506</td>\n",
       "      <td>98.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>522</td>\n",
       "      <td>0.312261</td>\n",
       "      <td>m. holliday</td>\n",
       "      <td>24</td>\n",
       "      <td>matt holliday</td>\n",
       "      <td>*7/D</td>\n",
       "      <td>2011</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312</td>\n",
       "      <td>69.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.390</td>\n",
       "      <td>95</td>\n",
       "      <td>103</td>\n",
       "      <td>9</td>\n",
       "      <td>0.532</td>\n",
       "      <td>93.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AB       AVG     Abbr_Name  HR            Name Pos Summary  \\\n",
       "0  508  0.322835     a. pujols  34   albert pujols          *3   \n",
       "1  528  0.289773    p. fielder  37  prince fielder        *3/D   \n",
       "2  521  0.320537    h. ramirez  24  hanley ramirez          *6   \n",
       "3  447  0.286353  a. rodriguez  31  alex rodriguez         *5D   \n",
       "4  522  0.312261   m. holliday  24   matt holliday        *7/D   \n",
       "\n",
       "   Prediction_Season   R  RBI  SB     ...      actual_AVG  actual_BB  \\\n",
       "0               2011  96  104   9     ...           0.312      103.0   \n",
       "1               2011  88  106   3     ...           0.261      114.0   \n",
       "2               2011  97   75  30     ...           0.300       64.0   \n",
       "3               2011  85   93  15     ...           0.270       59.0   \n",
       "4               2011  90   93  16     ...           0.312       69.0   \n",
       "\n",
       "   actual_HR  actual_OBP  actual_R  actual_RBI  actual_SB  actual_SLG  \\\n",
       "0         42       0.414       115         118         14       0.596   \n",
       "1         32       0.401        94          83          1       0.471   \n",
       "2         21       0.378        92          76         32       0.475   \n",
       "3         30       0.341        74         125          4       0.506   \n",
       "4         28       0.390        95         103          9       0.532   \n",
       "\n",
       "   actual_SO  actual_age  \n",
       "0       76.0        30.0  \n",
       "1      138.0        26.0  \n",
       "2       93.0        26.0  \n",
       "3       98.0        34.0  \n",
       "4       93.0        30.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marcel_hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB                   0\n",
      "AVG                  0\n",
      "Abbr_Name            0\n",
      "HR                   0\n",
      "Name                 0\n",
      "Pos Summary          0\n",
      "Prediction_Season    0\n",
      "R                    0\n",
      "RBI                  0\n",
      "SB                   0\n",
      "Season               0\n",
      "actual_2B            0\n",
      "actual_3B            0\n",
      "actual_AB            0\n",
      "actual_AVG           0\n",
      "actual_BB            0\n",
      "actual_HR            0\n",
      "actual_OBP           0\n",
      "actual_R             0\n",
      "actual_RBI           0\n",
      "actual_SB            0\n",
      "actual_SLG           0\n",
      "actual_SO            0\n",
      "actual_age           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print marcel_hitters.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbr_Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>ERA</th>\n",
       "      <th>IP</th>\n",
       "      <th>K</th>\n",
       "      <th>Name</th>\n",
       "      <th>Season</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>actual_BB</th>\n",
       "      <th>actual_BF</th>\n",
       "      <th>actual_ERA</th>\n",
       "      <th>actual_FIP</th>\n",
       "      <th>actual_H</th>\n",
       "      <th>actual_IP</th>\n",
       "      <th>actual_K</th>\n",
       "      <th>actual_SV</th>\n",
       "      <th>actual_W</th>\n",
       "      <th>actual_WHIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t. lincecum</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>195.0</td>\n",
       "      <td>218</td>\n",
       "      <td>tim lincecum</td>\n",
       "      <td>2010</td>\n",
       "      <td>13</td>\n",
       "      <td>1.138462</td>\n",
       "      <td>76.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>3.15</td>\n",
       "      <td>194.0</td>\n",
       "      <td>212.1</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c. carpenter</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.01</td>\n",
       "      <td>157.0</td>\n",
       "      <td>115</td>\n",
       "      <td>chris carpenter</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>1.152866</td>\n",
       "      <td>63.0</td>\n",
       "      <td>969.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.69</td>\n",
       "      <td>214.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a. bailey</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.09</td>\n",
       "      <td>67.0</td>\n",
       "      <td>63</td>\n",
       "      <td>andrew bailey</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>1.119403</td>\n",
       "      <td>13.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2.96</td>\n",
       "      <td>34.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j. broxton</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.09</td>\n",
       "      <td>70.0</td>\n",
       "      <td>83</td>\n",
       "      <td>jonathan broxton</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>1.157143</td>\n",
       "      <td>28.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3.01</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.1</td>\n",
       "      <td>73</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>1.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m. adams</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48</td>\n",
       "      <td>mike adams</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>1.140000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Abbr_Name   Age   ERA     IP    K              Name  Season   W  \\\n",
       "0   t. lincecum  26.0  2.88  195.0  218      tim lincecum    2010  13   \n",
       "1  c. carpenter  35.0  3.01  157.0  115   chris carpenter    2010  12   \n",
       "2     a. bailey  26.0  3.09   67.0   63     andrew bailey    2010   4   \n",
       "3    j. broxton  26.0  3.09   70.0   83  jonathan broxton    2010   5   \n",
       "4      m. adams  31.0  3.15   50.0   48        mike adams    2010   2   \n",
       "\n",
       "       WHIP  actual_BB  actual_BF  actual_ERA  actual_FIP  actual_H  \\\n",
       "0  1.138462       76.0      897.0        3.43        3.15     194.0   \n",
       "1  1.152866       63.0      969.0        3.22        3.69     214.0   \n",
       "2  1.119403       13.0      189.0        1.47        2.96      34.0   \n",
       "3  1.157143       28.0      271.0        4.04        3.01      64.0   \n",
       "4  1.140000       23.0      268.0        1.76        2.31      48.0   \n",
       "\n",
       "   actual_IP  actual_K  actual_SV  actual_W  actual_WHIP  \n",
       "0      212.1       231          0        16        1.272  \n",
       "1      235.0       179          0        16        1.179  \n",
       "2       49.0        42         25         1        0.959  \n",
       "3       62.1        73         22         5        1.476  \n",
       "4       66.2        73          0         4        1.065  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marcel_pitchers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abbr_Name      0\n",
      "Age            0\n",
      "ERA            0\n",
      "IP             0\n",
      "K              0\n",
      "Name           0\n",
      "Season         0\n",
      "W              0\n",
      "WHIP           0\n",
      "actual_BB      0\n",
      "actual_BF      0\n",
      "actual_ERA     0\n",
      "actual_FIP     0\n",
      "actual_H       0\n",
      "actual_IP      0\n",
      "actual_K       0\n",
      "actual_SV      0\n",
      "actual_W       0\n",
      "actual_WHIP    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print marcel_pitchers.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table of some basic summary statistics for the Marcel hitters data, followed by the same for the Marcel pitchers data. It can also be seen from the summary statistics that nothing seems out of range, and the values reported make sense given the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AVG</th>\n",
       "      <th>HR</th>\n",
       "      <th>Prediction_Season</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>Season</th>\n",
       "      <th>actual_2B</th>\n",
       "      <th>actual_3B</th>\n",
       "      <th>...</th>\n",
       "      <th>actual_AVG</th>\n",
       "      <th>actual_BB</th>\n",
       "      <th>actual_HR</th>\n",
       "      <th>actual_OBP</th>\n",
       "      <th>actual_R</th>\n",
       "      <th>actual_RBI</th>\n",
       "      <th>actual_SB</th>\n",
       "      <th>actual_SLG</th>\n",
       "      <th>actual_SO</th>\n",
       "      <th>actual_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "      <td>1871.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>400.636024</td>\n",
       "      <td>0.264954</td>\n",
       "      <td>12.459647</td>\n",
       "      <td>2013.490647</td>\n",
       "      <td>53.720470</td>\n",
       "      <td>51.006948</td>\n",
       "      <td>7.979156</td>\n",
       "      <td>2012.490647</td>\n",
       "      <td>21.868520</td>\n",
       "      <td>2.265099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259387</td>\n",
       "      <td>38.706574</td>\n",
       "      <td>12.680385</td>\n",
       "      <td>0.324669</td>\n",
       "      <td>54.342598</td>\n",
       "      <td>52.334046</td>\n",
       "      <td>7.714057</td>\n",
       "      <td>0.408976</td>\n",
       "      <td>85.894174</td>\n",
       "      <td>28.959380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>105.615495</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>6.645199</td>\n",
       "      <td>1.702717</td>\n",
       "      <td>17.546833</td>\n",
       "      <td>18.837681</td>\n",
       "      <td>7.421539</td>\n",
       "      <td>1.702717</td>\n",
       "      <td>9.543081</td>\n",
       "      <td>2.390323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031349</td>\n",
       "      <td>20.161645</td>\n",
       "      <td>9.131390</td>\n",
       "      <td>0.035828</td>\n",
       "      <td>23.408388</td>\n",
       "      <td>24.950885</td>\n",
       "      <td>9.838591</td>\n",
       "      <td>0.069251</td>\n",
       "      <td>34.362779</td>\n",
       "      <td>3.884352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>0.204698</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>320.000000</td>\n",
       "      <td>0.251424</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>0.264916</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.403000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>491.000000</td>\n",
       "      <td>0.277039</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>593.000000</td>\n",
       "      <td>0.329218</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.474000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.649000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AB          AVG           HR  Prediction_Season            R  \\\n",
       "count  1871.000000  1871.000000  1871.000000        1871.000000  1871.000000   \n",
       "mean    400.636024     0.264954    12.459647        2013.490647    53.720470   \n",
       "std     105.615495     0.019227     6.645199           1.702717    17.546833   \n",
       "min     177.000000     0.204698     2.000000        2011.000000    19.000000   \n",
       "25%     320.000000     0.251424     7.000000        2012.000000    40.000000   \n",
       "50%     418.000000     0.264916    11.000000        2014.000000    54.000000   \n",
       "75%     491.000000     0.277039    17.000000        2015.000000    67.000000   \n",
       "max     593.000000     0.329218    39.000000        2016.000000   104.000000   \n",
       "\n",
       "               RBI           SB       Season    actual_2B    actual_3B  \\\n",
       "count  1871.000000  1871.000000  1871.000000  1871.000000  1871.000000   \n",
       "mean     51.006948     7.979156  2012.490647    21.868520     2.265099   \n",
       "std      18.837681     7.421539     1.702717     9.543081     2.390323   \n",
       "min      17.000000     1.000000  2010.000000     2.000000     0.000000   \n",
       "25%      36.000000     3.000000  2011.000000    14.000000     0.000000   \n",
       "50%      50.000000     5.000000  2013.000000    21.000000     2.000000   \n",
       "75%      65.000000    10.000000  2014.000000    28.000000     3.000000   \n",
       "max     119.000000    51.000000  2015.000000    55.000000    16.000000   \n",
       "\n",
       "          ...        actual_AVG    actual_BB    actual_HR   actual_OBP  \\\n",
       "count     ...       1871.000000  1871.000000  1871.000000  1871.000000   \n",
       "mean      ...          0.259387    38.706574    12.680385     0.324669   \n",
       "std       ...          0.031349    20.161645     9.131390     0.035828   \n",
       "min       ...          0.146000     4.000000     0.000000     0.174000   \n",
       "25%       ...          0.239000    24.000000     6.000000     0.301000   \n",
       "50%       ...          0.259000    35.000000    11.000000     0.323000   \n",
       "75%       ...          0.281000    50.000000    18.000000     0.347000   \n",
       "max       ...          0.359000   143.000000    54.000000     0.474000   \n",
       "\n",
       "          actual_R   actual_RBI    actual_SB   actual_SLG    actual_SO  \\\n",
       "count  1871.000000  1871.000000  1871.000000  1871.000000  1871.000000   \n",
       "mean     54.342598    52.334046     7.714057     0.408976    85.894174   \n",
       "std      23.408388    24.950885     9.838591     0.069251    34.362779   \n",
       "min       4.000000     8.000000     0.000000     0.187000    21.000000   \n",
       "25%      35.500000    32.000000     1.000000     0.361000    60.000000   \n",
       "50%      52.000000    48.000000     4.000000     0.403000    82.000000   \n",
       "75%      72.000000    69.000000    11.000000     0.453000   106.000000   \n",
       "max     136.000000   139.000000    68.000000     0.649000   222.000000   \n",
       "\n",
       "        actual_age  \n",
       "count  1871.000000  \n",
       "mean     28.959380  \n",
       "std       3.884352  \n",
       "min      20.000000  \n",
       "25%      26.000000  \n",
       "50%      29.000000  \n",
       "75%      32.000000  \n",
       "max      43.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marcel_hitters.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ERA</th>\n",
       "      <th>IP</th>\n",
       "      <th>K</th>\n",
       "      <th>Season</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>actual_BB</th>\n",
       "      <th>actual_BF</th>\n",
       "      <th>actual_ERA</th>\n",
       "      <th>actual_FIP</th>\n",
       "      <th>actual_H</th>\n",
       "      <th>actual_IP</th>\n",
       "      <th>actual_K</th>\n",
       "      <th>actual_SV</th>\n",
       "      <th>actual_W</th>\n",
       "      <th>actual_WHIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "      <td>2354.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.781223</td>\n",
       "      <td>3.893755</td>\n",
       "      <td>91.398343</td>\n",
       "      <td>75.630416</td>\n",
       "      <td>2012.525064</td>\n",
       "      <td>5.287596</td>\n",
       "      <td>1.310539</td>\n",
       "      <td>31.328802</td>\n",
       "      <td>405.767630</td>\n",
       "      <td>3.891619</td>\n",
       "      <td>3.908008</td>\n",
       "      <td>92.197961</td>\n",
       "      <td>95.849618</td>\n",
       "      <td>80.121071</td>\n",
       "      <td>3.078590</td>\n",
       "      <td>5.534410</td>\n",
       "      <td>1.309510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.998424</td>\n",
       "      <td>0.514722</td>\n",
       "      <td>50.613519</td>\n",
       "      <td>42.257817</td>\n",
       "      <td>1.700606</td>\n",
       "      <td>3.420166</td>\n",
       "      <td>0.094917</td>\n",
       "      <td>19.083233</td>\n",
       "      <td>253.188384</td>\n",
       "      <td>1.293373</td>\n",
       "      <td>0.941681</td>\n",
       "      <td>60.344611</td>\n",
       "      <td>60.833606</td>\n",
       "      <td>52.789000</td>\n",
       "      <td>8.898122</td>\n",
       "      <td>4.590207</td>\n",
       "      <td>0.225391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943683</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.251694</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>3.002500</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.163250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.313433</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>68.100000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>4.240000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.372190</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>634.000000</td>\n",
       "      <td>4.610000</td>\n",
       "      <td>4.470000</td>\n",
       "      <td>148.750000</td>\n",
       "      <td>147.075000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.580000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.655914</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>1009.000000</td>\n",
       "      <td>10.690000</td>\n",
       "      <td>8.570000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.357000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age          ERA           IP            K       Season  \\\n",
       "count  2354.000000  2354.000000  2354.000000  2354.000000  2354.000000   \n",
       "mean     28.781223     3.893755    91.398343    75.630416  2012.525064   \n",
       "std       3.998424     0.514722    50.613519    42.257817     1.700606   \n",
       "min      20.000000     2.210000    25.000000    18.000000  2010.000000   \n",
       "25%      26.000000     3.520000    55.000000    45.000000  2011.000000   \n",
       "50%      28.000000     3.900000    68.000000    61.000000  2013.000000   \n",
       "75%      31.000000     4.240000   137.000000   103.000000  2014.000000   \n",
       "max      49.000000     5.580000   209.000000   218.000000  2015.000000   \n",
       "\n",
       "                 W         WHIP    actual_BB    actual_BF   actual_ERA  \\\n",
       "count  2354.000000  2354.000000  2354.000000  2354.000000  2354.000000   \n",
       "mean      5.287596     1.310539    31.328802   405.767630     3.891619   \n",
       "std       3.420166     0.094917    19.083233   253.188384     1.293373   \n",
       "min       1.000000     0.943683     3.000000    90.000000     0.600000   \n",
       "25%       3.000000     1.251694    17.000000   217.000000     3.002500   \n",
       "50%       4.000000     1.313433    26.000000   285.000000     3.750000   \n",
       "75%       8.000000     1.372190    43.000000   634.000000     4.610000   \n",
       "max      17.000000     1.655914   105.000000  1009.000000    10.690000   \n",
       "\n",
       "        actual_FIP     actual_H    actual_IP     actual_K    actual_SV  \\\n",
       "count  2354.000000  2354.000000  2354.000000  2354.000000  2354.000000   \n",
       "mean      3.908008    92.197961    95.849618    80.121071     3.078590   \n",
       "std       0.941681    60.344611    60.833606    52.789000     8.898122   \n",
       "min       0.780000    11.000000    25.100000     7.000000     0.000000   \n",
       "25%       3.280000    45.000000    51.000000    41.000000     0.000000   \n",
       "50%       3.850000    64.000000    68.100000    63.000000     0.000000   \n",
       "75%       4.470000   148.750000   147.075000   109.000000     1.000000   \n",
       "max       8.570000   262.000000   251.000000   301.000000    51.000000   \n",
       "\n",
       "          actual_W  actual_WHIP  \n",
       "count  2354.000000  2354.000000  \n",
       "mean      5.534410     1.309510  \n",
       "std       4.590207     0.225391  \n",
       "min       0.000000     0.565000  \n",
       "25%       2.000000     1.163250  \n",
       "50%       4.000000     1.298000  \n",
       "75%       8.000000     1.440000  \n",
       "max      24.000000     2.357000  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marcel_pitchers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, we will now go through similar processes for the remaining five sources of projection data, but in considerably less detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FanGraphs\n",
    "FanGraphs is a company-run website that provides historical major and minor league baseball statistics, analysis, and projections. Below, we scrape their projections from each season of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ========================== CREATE DATAFRAMES OF FANGRAPHS PITCHER & HITTER PROJECTIONS ==============================\n",
    "\n",
    "# Set up our hitter and pitcher pandas DataFrames for FanGraphs method\n",
    "fangraphs_hitters = pd.DataFrame()\n",
    "fangraphs_pitchers = pd.DataFrame()\n",
    "\n",
    "# for each year of projections read in the csv file and append it to the appropriate df\n",
    "ID=[2010, 2011, 2012, 2013, 2014, 2015]\n",
    "for i in ID:\n",
    "    df = pd.read_csv('CSV_files/fangraphs/fans_hitters_{}.csv'.format(i))\n",
    "    fangraphs_hitters = fangraphs_hitters.append(df, ignore_index = True)\n",
    "    df2 = pd.read_csv('CSV_files/fangraphs/fans_pitchers_{}.csv'.format(i))\n",
    "    fangraphs_pitchers = fangraphs_pitchers.append(df2, ignore_index = True)\n",
    "\n",
    "# only keep statistics we are interested in \n",
    "fangraphs_hitters = fangraphs_hitters[['Name', 'AB', 'HR', 'R', 'RBI', 'SB', 'AVG', 'season']]\n",
    "fangraphs_pitchers = fangraphs_pitchers[['Name', 'W', 'ERA', 'IP', 'K','SV', 'WHIP', 'season']]\n",
    "fangraphs_hitters = fangraphs_hitters.rename(columns = {'season' : 'Season'})\n",
    "fangraphs_pitchers = fangraphs_pitchers.rename(columns = {'season' : 'Season'})\n",
    "\n",
    "fangraphs_pitchers['Name'] = fangraphs_pitchers['Name'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using a function defined previously, change names to lower case for uniformity\n",
    "\n",
    "fangraphs_pitchers['Name'] = fangraphs_pitchers['Name'].apply(lower_names)\n",
    "fangraphs_hitters['Name'] = fangraphs_hitters['Name'].apply(lower_names)\n",
    "\n",
    "fangraphs_pitchers['First'], fangraphs_pitchers['First_initial'], fangraphs_pitchers['Last'] = \\\n",
    "    fangraphs_pitchers['Name'].apply(split_names_first),fangraphs_pitchers['Name'].apply(split_names_first_initial),\\\n",
    "    fangraphs_pitchers['Name'].apply(split_names_last)\n",
    "fangraphs_pitchers['Abbr_Name'] = fangraphs_pitchers['First_initial'] + ' ' + fangraphs_pitchers['Last']\n",
    "fangraphs_hitters['First'], fangraphs_hitters['First_initial'], fangraphs_hitters['Last'] = \\\n",
    "    fangraphs_hitters['Name'].apply(split_names_first),fangraphs_hitters['Name'].apply(split_names_first_initial),\\\n",
    "    fangraphs_hitters['Name'].apply(split_names_last)\n",
    "fangraphs_hitters['Abbr_Name'] = fangraphs_hitters['First_initial'] + ' ' + fangraphs_hitters['Last']\n",
    "\n",
    "del fangraphs_hitters['First'], fangraphs_hitters['First_initial'], fangraphs_hitters['Last']\n",
    "del fangraphs_pitchers['First'], fangraphs_pitchers['First_initial'], fangraphs_pitchers['Last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign columns to the correct datatypes\n",
    "fangraphs_hitters[\"AB\"] = fangraphs_hitters[\"AB\"].astype(str)\n",
    "fangraphs_hitters[\"RBI\"] = fangraphs_hitters[\"RBI\"].astype(int)\n",
    "fangraphs_hitters[\"R\"] = fangraphs_hitters[\"R\"].astype(int)\n",
    "fangraphs_hitters[\"HR\"] = fangraphs_hitters[\"HR\"].astype(int)\n",
    "fangraphs_hitters[\"SB\"] = fangraphs_hitters[\"SB\"].astype(int)\n",
    "fangraphs_hitters[\"Season\"] = fangraphs_hitters[\"Season\"].astype(int)\n",
    "\n",
    "fangraphs_pitchers[\"K\"] = fangraphs_pitchers[\"K\"].astype(int)\n",
    "fangraphs_pitchers[\"W\"] = fangraphs_pitchers[\"W\"].astype(int)\n",
    "fangraphs_pitchers[\"Season\"] = fangraphs_pitchers[\"Season\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Take a subset of the fangraphs dataframe to only include players in the actual statistics dataframes\n",
    "new_df_pitch = find_names(pitchersDF, fangraphs_pitchers, season)\n",
    "new_df_hit = find_names(hittersDF, fangraphs_hitters, season)\n",
    "\n",
    "fangraphs_pitchers = new_df_pitch[0].append(new_df_pitch[3])\n",
    "fangraphs_hitters = new_df_hit[0].append(new_df_hit[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fangraphs_hitters[\"AB\"] = pd.to_numeric(fangraphs_hitters.AB)\n",
    "fangraphs_hitters[\"AB\"] = fangraphs_hitters[\"AB\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steamer\n",
    "Steamer Projections provides statistical projections for major league baseball players. Below, we will obtain their results for each of our seasons of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =========================== CREATE DATAFRAMES OF STEAMER PITCHER & HITTER PROJECTIONS ==============================\n",
    "\n",
    "# Set up our hitter and pitcher Pandas DataFrames for Steamer method\n",
    "steamer_hitters = pd.DataFrame()\n",
    "steamer_pitchers = pd.DataFrame()\n",
    "\n",
    "#for each year of projections read in the csv file and append it to the apprpriate df\n",
    "\n",
    "ID=[2010, 2011, 2012, 2013, 2014, 2015]\n",
    "for i in ID:\n",
    "    df = pd.read_csv('CSV_files/steamer/steamer_hitters_{}.csv'.format(i))\n",
    "    steamer_hitters = steamer_hitters.append(df, ignore_index = True)\n",
    "    df2 = pd.read_csv('CSV_files/steamer/steamer_pitchers_{}.csv'.format(i))\n",
    "    steamer_pitchers = steamer_pitchers.append(df2, ignore_index = True)\n",
    "    \n",
    "# only keep statistics we are interested in \n",
    "steamer_hitters = steamer_hitters[['Name', 'AB', 'HR', 'R', 'RBI', 'SB', 'AVG', 'season']]\n",
    "steamer_pitchers = steamer_pitchers[['Name', 'W', 'ERA', 'IP', 'K','SV', 'WHIP', 'season']]\n",
    "steamer_hitters = steamer_hitters.rename(columns = {'season' : 'Season'})\n",
    "steamer_pitchers = steamer_pitchers.rename(columns = {'season' : 'Season'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using a function defined previously, change names to lower case for uniformity\n",
    "steamer_pitchers['Name'] = steamer_pitchers['Name'].apply(lower_names)\n",
    "steamer_hitters['Name'] = steamer_hitters['Name'].apply(lower_names)\n",
    "\n",
    "steamer_pitchers['First'], steamer_pitchers['First_initial'], steamer_pitchers['Last'] = \\\n",
    "    steamer_pitchers['Name'].apply(split_names_first),steamer_pitchers['Name'].apply(split_names_first_initial),\\\n",
    "    steamer_pitchers['Name'].apply(split_names_last)\n",
    "steamer_pitchers['Abbr_Name'] = steamer_pitchers['First_initial'] + ' ' + steamer_pitchers['Last']\n",
    "steamer_hitters['First'], steamer_hitters['First_initial'], steamer_hitters['Last'] = \\\n",
    "    steamer_hitters['Name'].apply(split_names_first),steamer_hitters['Name'].apply(split_names_first_initial),\\\n",
    "    steamer_hitters['Name'].apply(split_names_last)\n",
    "steamer_hitters['Abbr_Name'] = steamer_hitters['First_initial'] + ' ' + steamer_hitters['Last']\n",
    "del steamer_hitters['First'], steamer_hitters['First_initial'], steamer_hitters['Last']\n",
    "del steamer_pitchers['First'], steamer_pitchers['First_initial'], steamer_pitchers['Last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign columns to the correct datatypes\n",
    "#steamer_hitters[\"AB\"] = pd.to_numeric(steamer_hitters.AB)\n",
    "steamer_hitters[\"AB\"] = steamer_hitters[\"AB\"].astype(str)\n",
    "steamer_hitters[\"RBI\"] = steamer_hitters[\"RBI\"].astype(int)\n",
    "steamer_hitters[\"R\"] = steamer_hitters[\"R\"].astype(int)\n",
    "steamer_hitters[\"HR\"] = steamer_hitters[\"HR\"].astype(int)\n",
    "steamer_hitters[\"SB\"] = steamer_hitters[\"SB\"].astype(int)\n",
    "steamer_hitters[\"Season\"] = steamer_hitters[\"Season\"].astype(int)\n",
    "\n",
    "steamer_pitchers[\"K\"] = steamer_pitchers[\"K\"].astype(int)\n",
    "steamer_pitchers[\"W\"] = steamer_pitchers[\"W\"].astype(int)\n",
    "steamer_pitchers[\"Season\"] = steamer_pitchers[\"Season\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Take a subset of the steamer dataframes to only include players in the actual statistics dataframes\n",
    "new_df_pitch = find_names(pitchersDF, steamer_pitchers, season)\n",
    "new_df_hit = find_names(hittersDF, steamer_hitters, season)\n",
    "\n",
    "steamer_pitchers = new_df_pitch[0].append(new_df_pitch[3])\n",
    "steamer_hitters = new_df_hit[0].append(new_df_hit[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guru\n",
    "The Baseball Guru is another provider of major league baseball statistics, rankings, and forecasts. We will now scrape their projections from 2010-2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ============================= CREATE DATAFRAMES OF GURU PITCHER & HITTER PROJECTIONS ================================\n",
    "\n",
    "# Set up our hitter and pitcher Pandas dataframes for Guru method\n",
    "guru_hitters = pd.DataFrame()\n",
    "guru_pitchers = pd.DataFrame()\n",
    "\n",
    "# for each year of projections read in the csv file and append it to the apprpriate df\n",
    "ID=[2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "for i in ID:\n",
    "    df = pd.read_csv('CSV_files/guru/guru_hitters_{}.csv'.format(i))\n",
    "    guru_hitters = guru_hitters.append(df, ignore_index = True)\n",
    "    \n",
    "    if i != 2015: # Special exception because Guru doesn't have projections for pitchers in 2015\n",
    "        df2 = pd.read_csv('CSV_files/guru/guru_pitchers_{}.csv'.format(i))\n",
    "        guru_pitchers = guru_pitchers.append(df2, ignore_index = True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# only keep statistics we are interested in \n",
    "guru_hitters = guru_hitters[['Name', 'AB', 'HR', 'R', 'RBI', 'SB', 'AVG', 'season']]\n",
    "guru_pitchers = guru_pitchers[['Name', 'W', 'ERA', 'IP', 'K','SV', 'WHIP', 'season']]\n",
    "guru_hitters = guru_hitters.rename(columns = {'season' : 'Season'})\n",
    "guru_pitchers = guru_pitchers.rename(columns = {'season' : 'Season'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop null values\n",
    "guru_hitters.dropna(inplace=True)\n",
    "guru_pitchers.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace -'s values with 0's\n",
    "guru_pitchers['SV'] = guru_pitchers['SV'].replace(\".*[\\-].* \",\"0\", regex=True).astype(int)\n",
    "guru_hitters['HR'] = guru_hitters['HR'].replace(\".*[\\-].*\", \"0\", regex=True).astype(int)\n",
    "guru_hitters['SB'] = guru_hitters['SB'].replace(\".*[\\-]*\", \"0\", regex=True).astype(int)\n",
    "guru_pitchers['W'] = guru_pitchers['W'].replace(\".*[\\-]*\", \"0\", regex=True).astype(int)\n",
    "\n",
    "# using a function defined previously, change names to lower case for uniformity\n",
    "\n",
    "guru_pitchers['Name'] = guru_pitchers['Name'].apply(lower_names)\n",
    "guru_hitters['Name'] = guru_hitters['Name'].apply(lower_names)\n",
    "\n",
    "guru_pitchers['First'], guru_pitchers['First_initial'], guru_pitchers['Last'] = \\\n",
    "    guru_pitchers['Name'].apply(split_names_first),guru_pitchers['Name'].apply(split_names_first_initial),\\\n",
    "    guru_pitchers['Name'].apply(split_names_last)\n",
    "guru_pitchers['Abbr_Name'] = guru_pitchers['First_initial'] + ' ' + guru_pitchers['Last']\n",
    "guru_hitters['First'], guru_hitters['First_initial'], guru_hitters['Last'] = \\\n",
    "    guru_hitters['Name'].apply(split_names_first),guru_hitters['Name'].apply(split_names_first_initial),\\\n",
    "    guru_hitters['Name'].apply(split_names_last)\n",
    "guru_hitters['Abbr_Name'] = guru_hitters['First_initial'] + ' ' + guru_hitters['Last']\n",
    "del guru_hitters['First'], guru_hitters['First_initial'], guru_hitters['Last']\n",
    "del guru_pitchers['First'], guru_pitchers['First_initial'], guru_pitchers['Last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign columns to the correct datatypes\n",
    "guru_hitters[\"AB\"] = pd.to_numeric(guru_hitters.AB)\n",
    "guru_hitters[\"AB\"] = guru_hitters[\"AB\"].astype(int)\n",
    "guru_hitters[\"RBI\"] = guru_hitters[\"RBI\"].astype(int)\n",
    "guru_hitters[\"R\"] = guru_hitters[\"R\"].astype(int)\n",
    "guru_hitters[\"HR\"] = guru_hitters[\"HR\"].astype(int)\n",
    "guru_hitters[\"SB\"] = guru_hitters[\"SB\"].astype(int)\n",
    "guru_hitters[\"Season\"] = guru_hitters[\"Season\"].astype(int)\n",
    "\n",
    "guru_pitchers[\"K\"] = guru_pitchers[\"K\"].astype(int)\n",
    "guru_pitchers[\"W\"] = guru_pitchers[\"W\"].astype(int)\n",
    "guru_pitchers[\"Season\"] = guru_pitchers[\"Season\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Take a subset of the fangraphs dataframe to only include players in the actual statistics dataframes\n",
    "seasons = [2010, 2011, 2012, 2013, 2014, 2016]\n",
    "\n",
    "#use the find names function defined earlier\n",
    "new_df_pitch = find_names(pitchersDF, guru_pitchers, seasons)\n",
    "new_df_hit = find_names(hittersDF, guru_hitters, seasons)\n",
    "\n",
    "guru_pitchers = new_df_pitch[0].append(new_df_pitch[3])\n",
    "guru_hitters = new_df_hit[0].append(new_df_hit[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESPN\n",
    "ESPN is a sports television network and entertainment company that also provides analysis, projections, and rankings for collegiate and professional sports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ============================= CREATE DATAFRAMES OF ESPN PITCHER & HITTER PROJECTIONS ================================\n",
    "\n",
    "# empty lists to append to for each year of information\n",
    "espn_hitters = []\n",
    "espn_pitchers = []\n",
    "\n",
    "# append to pitchers dataframe\n",
    "for ID in os.listdir('CSV_files/espn_pitchers/'):\n",
    "    if ID not in '.listing':\n",
    "        with open(os.path.join('./CSV_files/espn_pitchers/', ID)) as inFile:\n",
    "            espn_pitchers.append(pd.read_csv(inFile))\n",
    "            \n",
    "# append to hitters dataframe\n",
    "for ID in os.listdir('CSV_files/espn_hitters/'):\n",
    "    if ID not in '.listing':\n",
    "        with open(os.path.join('./CSV_files/espn_hitters/', ID)) as inFile:\n",
    "            espn_hitters.append(pd.read_csv(inFile))\n",
    "\n",
    "# concatenate master lists into dataframes            \n",
    "espn_pitchers = pd.concat(espn_pitchers)\n",
    "espn_hitters = pd.concat(espn_hitters)\n",
    "\n",
    "# keep only the stats we are interested in and rename columns to match our other dataframes\n",
    "espn_pitchers = espn_pitchers[['name', '    K', '    W', '   IP', '   SV', '  ERA', ' WHIP', 'season']]\n",
    "espn_pitchers.columns = ['Name', 'K', 'W', 'IP', 'SV', 'ERA', 'WHIP', 'Season']\n",
    "espn_hitters = espn_hitters[['Player', '   AB', 'RBI', 'R','HR', 'SB', 'AVG', 'Season']]\n",
    "espn_hitters.columns = ['Name', 'AB', 'RBI', 'R','HR', 'SB', 'AVG', 'Season']\n",
    "espn_hitters['Name'] = espn_hitters['Name'].astype(str)\n",
    "espn_pitchers['Name'] = espn_pitchers['Name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert names to all lower case letters for uniformity\n",
    "espn_pitchers['Name'] = espn_pitchers['Name'].apply(lower_names)\n",
    "espn_hitters['Name'] = espn_hitters['Name'].apply(lower_names)\n",
    "\n",
    "espn_pitchers['First'], espn_pitchers['First_initial'], espn_pitchers['Last'] = \\\n",
    "    espn_pitchers['Name'].apply(split_names_first),espn_pitchers['Name'].apply(split_names_first_initial),\\\n",
    "    espn_pitchers['Name'].apply(split_names_last)\n",
    "espn_pitchers['Abbr_Name'] = espn_pitchers['First_initial'] + ' ' + espn_pitchers['Last']\n",
    "espn_hitters['First'], espn_hitters['First_initial'], espn_hitters['Last'] = \\\n",
    "    espn_hitters['Name'].apply(split_names_first),espn_hitters['Name'].apply(split_names_first_initial),\\\n",
    "    espn_hitters['Name'].apply(split_names_last)\n",
    "espn_hitters['Abbr_Name'] = espn_hitters['First_initial'] + ' ' + espn_hitters['Last']\n",
    "del espn_hitters['First'], espn_hitters['First_initial'], espn_hitters['Last']\n",
    "del espn_pitchers['First'], espn_pitchers['First_initial'], espn_pitchers['Last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Take a subset of the espn dataframes to only include players in the actual statistics dataframes\n",
    "new_df_pitch = find_names(pitchersDF, espn_pitchers, season)\n",
    "new_df_hit = find_names(hittersDF, espn_hitters, season)\n",
    "\n",
    "espn_pitchers = new_df_pitch[0].append(new_df_pitch[3])\n",
    "espn_hitters = new_df_hit[0].append(new_df_hit[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop players without statistics\n",
    "\n",
    "# we want to use IP for the 2015 season, which is the only one that included this data\n",
    "espn_pitchers = espn_pitchers.replace(np.nan, -100)\n",
    "\n",
    "#convert invalid data and drop it\n",
    "espn_pitchers = espn_pitchers.replace(r'--', np.nan)\n",
    "espn_pitchers = espn_pitchers.dropna()\n",
    "espn_pitchers = espn_pitchers.replace(-100, np.nan)\n",
    "\n",
    "# want to use AB for the 2015 season, which is the only one that included this data\n",
    "espn_hitters = espn_hitters.replace(np.nan, -100)\n",
    "\n",
    "# convert invalid data and drop it\n",
    "espn_hitters = espn_hitters.replace(r'--', np.nan)\n",
    "espn_hitters = espn_hitters.dropna()\n",
    "espn_hitters = espn_hitters.replace(-100, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB                   1581\n",
      "AVG                     0\n",
      "Abbr_Name               0\n",
      "HR                      0\n",
      "Name                    0\n",
      "Pos Summary             0\n",
      "Prediction_Season       0\n",
      "R                       0\n",
      "RBI                     0\n",
      "SB                      0\n",
      "Season                  0\n",
      "actual_2B               0\n",
      "actual_3B               0\n",
      "actual_AB               0\n",
      "actual_AVG              0\n",
      "actual_BB               0\n",
      "actual_HR               0\n",
      "actual_OBP              0\n",
      "actual_R                0\n",
      "actual_RBI              0\n",
      "actual_SB               0\n",
      "actual_SLG              0\n",
      "actual_SO               0\n",
      "actual_age              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print espn_hitters.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign columns to the correct datatypes\n",
    "#espn_hitters[\"AB\"] = pd.to_numeric(espn_hitters.AB)\n",
    "#espn_hitters[\"AB\"] = espn_hitters[\"AB\"].astype(int)\n",
    "espn_hitters[\"AB\"] = espn_hitters[\"AB\"].astype(str)\n",
    "espn_hitters[\"RBI\"] = espn_hitters[\"RBI\"].astype(int)\n",
    "espn_hitters[\"R\"] = espn_hitters[\"R\"].astype(int)\n",
    "espn_hitters[\"HR\"] = espn_hitters[\"HR\"].astype(int)\n",
    "espn_hitters[\"SB\"] = espn_hitters[\"SB\"].astype(int)\n",
    "espn_hitters[\"Season\"] = espn_hitters[\"Season\"].astype(int)\n",
    "espn_hitters[\"AVG\"] = espn_hitters[\"AVG\"].astype(float)\n",
    "\n",
    "espn_pitchers[\"ERA\"] = espn_pitchers[\"ERA\"].astype(float)\n",
    "espn_pitchers[\"WHIP\"] = espn_pitchers[\"WHIP\"].astype(float)\n",
    "espn_pitchers[\"K\"] = espn_pitchers[\"K\"].astype(int)\n",
    "espn_pitchers[\"W\"] = espn_pitchers[\"W\"].astype(int)\n",
    "espn_pitchers[\"Season\"] = espn_pitchers[\"Season\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBS\n",
    "CBS Sports is the sports division of the commercial broadcast television network, CBS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ============================= CREATE DATAFRAMES OF CBS PITCHER & HITTER PROJECTIONS ================================\n",
    "\n",
    "# empty lists to append to for each year of information\n",
    "cbs_hitters = []\n",
    "cbs_pitchers = []\n",
    "\n",
    "# append to pitchers dataframe\n",
    "for ID in os.listdir('CSV_files/cbs_pitchers/'):\n",
    "    if ID not in '.listing':\n",
    "        with open(os.path.join('./CSV_files/cbs_pitchers/', ID)) as inFile:\n",
    "            cbs_pitchers.append(pd.read_csv(inFile))\n",
    "\n",
    "# append to hitters dataframe\n",
    "for ID in os.listdir('CSV_files/cbs_hitters/'):\n",
    "    if ID not in '.listing':\n",
    "        with open(os.path.join('./CSV_files/cbs_hitters/', ID)) as inFile:\n",
    "            cbs_hitters.append(pd.read_csv(inFile))\n",
    "            \n",
    "# concatenate master lists into dataframes            \n",
    "cbs_pitchers = pd.concat(cbs_pitchers)\n",
    "cbs_hitters = pd.concat(cbs_hitters)\n",
    "\n",
    "# keep only the columns with stats we care about\n",
    "cbs_pitchers = cbs_pitchers[['Name', 'SO', 'W', 'IP', 'ERA', 'WHIP', 'Season']]\n",
    "cbs_pitchers.columns = ['Name', 'K', 'W', 'IP', 'ERA', 'WHIP', 'Season']\n",
    "cbs_hitters = cbs_hitters[['Name', 'AB', 'RBI', 'R','HR', 'SB', 'AVG', 'Season']]\n",
    "cbs_hitters.columns = ['Name', 'AB', 'RBI', 'R','HR', 'SB', 'AVG', 'Season']\n",
    "\n",
    "cbs_hitters[\"Name\"] = cbs_hitters[\"Name\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert names to all lower case letters\n",
    "cbs_pitchers['Name'] = cbs_pitchers['Name'].apply(lower_names)\n",
    "cbs_hitters['Name'] = cbs_hitters['Name'].apply(lower_names)\n",
    "\n",
    "cbs_pitchers['First'], cbs_pitchers['First_initial'], cbs_pitchers['Last'] = \\\n",
    "    cbs_pitchers['Name'].apply(split_names_first),cbs_pitchers['Name'].apply(split_names_first_initial),\\\n",
    "    cbs_pitchers['Name'].apply(split_names_last)\n",
    "cbs_pitchers['Abbr_Name'] = cbs_pitchers['First_initial'] + ' ' + cbs_pitchers['Last']\n",
    "cbs_hitters['First'], cbs_hitters['First_initial'], cbs_hitters['Last'] = \\\n",
    "    cbs_hitters['Name'].apply(split_names_first),cbs_hitters['Name'].apply(split_names_first_initial),\\\n",
    "    cbs_hitters['Name'].apply(split_names_last)\n",
    "cbs_hitters['Abbr_Name'] = cbs_hitters['First_initial'] + ' ' + cbs_hitters['Last']\n",
    "del cbs_hitters['First'], cbs_hitters['First_initial'], cbs_hitters['Last']\n",
    "del cbs_pitchers['First'], cbs_pitchers['First_initial'], cbs_pitchers['Last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign columns to the correct datatype\n",
    "cbs_hitters['AB'] = pd.to_numeric(cbs_hitters.AB)\n",
    "cbs_hitters[\"AB\"] = cbs_hitters[\"AB\"].astype(int)\n",
    "cbs_hitters[\"RBI\"] = cbs_hitters[\"RBI\"].astype(int)\n",
    "#cbs_hitters[\"R\"] = cbs_hitters[\"R\"].astype(int)\n",
    "cbs_hitters[\"HR\"] = cbs_hitters[\"HR\"].astype(int)\n",
    "cbs_hitters[\"SB\"] = cbs_hitters[\"SB\"].astype(int)\n",
    "cbs_hitters[\"Season\"] = cbs_hitters[\"Season\"].astype(int)\n",
    "\n",
    "cbs_pitchers[\"K\"] = cbs_pitchers[\"K\"].astype(int)\n",
    "cbs_pitchers[\"W\"] = cbs_pitchers[\"W\"].astype(int)\n",
    "cbs_pitchers[\"Season\"] = cbs_pitchers[\"Season\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbs_hitters_2017 = cbs_hitters[cbs_hitters['Season']==2017]\n",
    "new_df_hit_predict = find_names2(hittersDF, cbs_hitters_2017, [2017])\n",
    "cbs_hitters_2017 = new_df_hit_predict[0].append(new_df_hit_predict[3])\n",
    "\n",
    "cbs_pitchers_2017 = cbs_pitchers[cbs_pitchers['Season']==2017]\n",
    "new_df_pitch_predict = find_names2(pitchersDF, cbs_pitchers_2017, [2017])\n",
    "cbs_pitchers_2017 = new_df_pitch_predict[0].append(new_df_pitch_predict[3])\n",
    "\n",
    "#Take a subset of the CBS dataframes to only include players in the actual statistics dataframes\n",
    "new_df_pitch = find_names(pitchersDF, cbs_pitchers, season)\n",
    "new_df_hit = find_names(hittersDF, cbs_hitters, season)\n",
    "\n",
    "cbs_pitchers = new_df_pitch[0].append(new_df_pitch[3])\n",
    "cbs_hitters = new_df_hit[0].append(new_df_hit[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcel didn't have projections for stolen bases, so we fill the missing values here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will use our function defined earlier to add columns to each of our dataframes. These columns are binary columns that have a 1 for a correct prediction and a 0 for an incorrect prediction. In the next section we will discuss \"correct\" predictions and \"incorrect\" predictions in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hitters_dict = {'RBI':7,'AVG':.01,'R':7, 'HR':5, 'SB':3}\n",
    "pitchers_dict = {'W':2,'K':15,'ERA':.2, 'WHIP':.05}\n",
    "#add the correct columns for our hitters dataframe\n",
    "add_correct_column(steamer_hitters, hitters_dict)\n",
    "add_correct_column(guru_hitters, hitters_dict)\n",
    "add_correct_column(marcel_hitters, hitters_dict)\n",
    "add_correct_column(espn_hitters, hitters_dict)\n",
    "add_correct_column(cbs_hitters, hitters_dict)\n",
    "add_correct_column(fangraphs_hitters, hitters_dict)\n",
    "\n",
    "#add the correct columns for our pitchers dataframe\n",
    "add_correct_column(steamer_pitchers, pitchers_dict)\n",
    "add_correct_column(guru_pitchers, pitchers_dict)\n",
    "add_correct_column(marcel_pitchers, pitchers_dict)\n",
    "add_correct_column(espn_pitchers, pitchers_dict)\n",
    "add_correct_column(cbs_pitchers, pitchers_dict)\n",
    "add_correct_column(fangraphs_pitchers, pitchers_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create new dataframes that we will use in our machine learning portion to try and classify correct and incorrect predictions. So, we join the previous years actual statistics to the projection statistics and then we also have the columns of binary classifications from the chunk of code above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df_pitch_predict = find_names2(pitchersDF, cbs_pitchers, season)\n",
    "new_df_hit_predict = find_names2(hittersDF, cbs_hitters, season)\n",
    "cbs_pitchers_predictions = new_df_pitch_predict[0].append(new_df_pitch_predict[3])\n",
    "cbs_hitters_predictions = new_df_hit_predict[0].append(new_df_hit_predict[3])\n",
    "\n",
    "new_df_pitch_predict = find_names2(pitchersDF, espn_pitchers, season)\n",
    "new_df_hit_predict = find_names2(hittersDF, espn_hitters, season)\n",
    "espn_pitchers_predictions = new_df_pitch_predict[0].append(new_df_pitch_predict[3])\n",
    "espn_hitters_predictions = new_df_hit_predict[0].append(new_df_hit_predict[3])\n",
    "\n",
    "new_df_pitch_predict = find_names2(pitchersDF, guru_pitchers, season)\n",
    "new_df_hit_predict = find_names2(hittersDF, guru_hitters, season)\n",
    "guru_pitchers_predictions = new_df_pitch_predict[0].append(new_df_pitch_predict[3])\n",
    "guru_hitters_predictions = new_df_hit_predict[0].append(new_df_hit_predict[3])\n",
    "\n",
    "new_df_pitch_predict = find_names2(pitchersDF, steamer_pitchers, season)\n",
    "new_df_hit_predict = find_names2(hittersDF, steamer_hitters, season)\n",
    "steamer_pitchers_predictions = new_df_pitch_predict[0].append(new_df_pitch_predict[3])\n",
    "steamer_hitters_predictions = new_df_hit_predict[0].append(new_df_hit_predict[3])\n",
    "\n",
    "new_df_pitch_predict = find_names2(pitchersDF, fangraphs_pitchers, season)\n",
    "new_df_hit_predict = find_names2(hittersDF, fangraphs_hitters, season)\n",
    "fangraphs_pitchers_predictions = new_df_pitch_predict[0].append(new_df_pitch_predict[3])\n",
    "fangraphs_hitters_predictions = new_df_hit_predict[0].append(new_df_hit_predict[3])\n",
    "\n",
    "new_df_pitch_predict = find_names2(pitchersDF, marcel_pitchers, season)\n",
    "new_df_hit_predict = find_names2(hittersDF, marcel_hitters, season)\n",
    "marcel_pitchers_predictions = new_df_pitch_predict[0].append(new_df_pitch_predict[3])\n",
    "marcel_hitters_predictions = new_df_hit_predict[0].append(new_df_hit_predict[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to now create a master dataframe that will posses all the data we will potentially need when it comes time to train our machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================= CREATE MASTER DATAFRAME OF ALL PLAYER PROJECTIONS ================================\n",
    "\n",
    "\n",
    "# create empty lists to append to\n",
    "hitter_predictions = []\n",
    "pitcher_predictions = []\n",
    "\n",
    "# create lists of methods to loop through, one for hitters & one for pitchers\n",
    "hitters_method_list = [cbs_hitters_predictions, espn_hitters_predictions, fangraphs_hitters_predictions, \\\n",
    "                       guru_hitters_predictions, marcel_hitters_predictions, steamer_hitters_predictions]\n",
    "pitchers_method_list = [cbs_pitchers_predictions, espn_pitchers_predictions, fangraphs_pitchers_predictions,\\\n",
    "                        guru_pitchers_predictions, marcel_pitchers_predictions, steamer_pitchers_predictions]\n",
    "\n",
    "# create a method column in each dataframe\n",
    "for i in xrange(len(hitters_method_list)):\n",
    "    hitters_method_list[i][\"method\"] = float(i) \n",
    "for i in xrange(len(pitchers_method_list)):\n",
    "    pitchers_method_list[i][\"method\"] = float(i)\n",
    "\n",
    "# loop through hitters projection dataframes\n",
    "for methodDF in hitters_method_list:\n",
    "    hitter_predictions.append(methodDF)\n",
    "# concatenate master hitter projections list into pandas DataFrame\n",
    "hitter_predictions = pd.concat(hitter_predictions)\n",
    "\n",
    "# loop through pitchers projection dataframes\n",
    "for methodDF in pitchers_method_list:\n",
    "    pitcher_predictions.append(methodDF)\n",
    "# concatenate master pitcher projections list into pandas DataFrame\n",
    "pitcher_predictions = pd.concat(pitcher_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hitters\n",
    "\n",
    "hitter_predictions = hitter_predictions.dropna()\n",
    "\n",
    "x_hitters = hitter_predictions[hitter_predictions.columns.difference(['Abbr_Name', 'Name', 'Pos Summary', 'Season', \\\n",
    "                        'correct_AVG', 'correct_HR', 'correct_R', 'correct_RBI', 'correct_SB', 'AB', 'Prediction_Season'])]\n",
    "\n",
    "to_predict_hitters = ['correct_AVG', 'correct_HR', 'correct_R', 'correct_RBI', 'correct_SB']\n",
    "\n",
    "\n",
    "# pitchers\n",
    "\n",
    "pitcher_predictions = pitcher_predictions.dropna()\n",
    "\n",
    "x_pitchers = pitcher_predictions[pitcher_predictions.columns.difference(['Abbr_Name', 'Name', 'Season',\\\n",
    "                'Prediction_Season', 'correct_ERA', 'correct_K', 'correct_W', 'correct_WHIP', 'IP', 'SV'])]\n",
    "\n",
    "to_predict_pitchers = ['correct_ERA', 'correct_K', 'correct_W', 'correct_WHIP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to now create a 2017 dataframe that will possess all the data we will potentially need when it comes time to run our machine learning algorithms and get classifications for this season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ================================= CREATE MASTER DATAFRAME OF ALL PLAYER PROJECTIONS ================================\n",
    "\n",
    "\n",
    "# create empty lists to append to\n",
    "hitter_predictions = []\n",
    "pitcher_predictions = []\n",
    "\n",
    "# create lists of methods to loop through, one for hitters & one for pitchers\n",
    "hitters_method_list = [cbs_hitters_predictions, espn_hitters_predictions, fangraphs_hitters_predictions, \\\n",
    "                       guru_hitters_predictions, marcel_hitters_predictions, steamer_hitters_predictions]\n",
    "pitchers_method_list = [cbs_pitchers_predictions, espn_pitchers_predictions, fangraphs_pitchers_predictions,\\\n",
    "                        guru_pitchers_predictions, marcel_pitchers_predictions, steamer_pitchers_predictions]\n",
    "\n",
    "# create a method column in each dataframe\n",
    "for i in xrange(len(hitters_method_list)):\n",
    "    hitters_method_list[i][\"method\"] = float(i) \n",
    "for i in xrange(len(pitchers_method_list)):\n",
    "    pitchers_method_list[i][\"method\"] = float(i)\n",
    "\n",
    "# loop through hitters projection dataframes\n",
    "for methodDF in hitters_method_list:\n",
    "    hitter_predictions.append(methodDF)\n",
    "# concatenate master hitter projections list into pandas DataFrame\n",
    "hitter_predictions = pd.concat(hitter_predictions)\n",
    "\n",
    "# loop through pitchers projection dataframes\n",
    "for methodDF in pitchers_method_list:\n",
    "    pitcher_predictions.append(methodDF)\n",
    "# concatenate master pitcher projections list into pandas DataFrame\n",
    "pitcher_predictions = pd.concat(pitcher_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hitters\n",
    "\n",
    "hitter_predictions = hitter_predictions.dropna()\n",
    "\n",
    "x_hitters = hitter_predictions[hitter_predictions.columns.difference(['Abbr_Name', 'Name', 'Pos Summary', 'Season', \\\n",
    "                        'correct_AVG', 'correct_HR', 'correct_R', 'correct_RBI', 'correct_SB', 'AB', 'Prediction_Season'])]\n",
    "\n",
    "to_predict_hitters = ['correct_AVG', 'correct_HR', 'correct_R', 'correct_RBI', 'correct_SB']\n",
    "\n",
    "\n",
    "# pitchers\n",
    "\n",
    "pitcher_predictions = pitcher_predictions.dropna()\n",
    "\n",
    "x_pitchers = pitcher_predictions[pitcher_predictions.columns.difference(['Abbr_Name', 'Name', 'Season',\\\n",
    "                'Prediction_Season', 'correct_ERA', 'correct_K', 'correct_W', 'correct_WHIP', 'IP', 'SV'])]\n",
    "\n",
    "to_predict_pitchers = ['correct_ERA', 'correct_K', 'correct_W', 'correct_WHIP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in & clean 2017 projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =========================== CREATE DATAFRAME OF 2017 STEAMER PITCHER & HITTER PROJECTIONS ===========================\n",
    "\n",
    "# Set up our hitter and pitcher Pandas DataFrames for 2017 Steamer method\n",
    "steamer_hitters_2017 = pd.DataFrame()\n",
    "steamer_pitchers_2017 = pd.DataFrame()\n",
    "\n",
    "# read in the csv file for 2017 and append it to the appropriate df\n",
    "\n",
    "steamer_hitters_2017 = pd.read_csv('CSV_files/steamer/steamer_hitters_{}.csv'.format(2017))\n",
    "steamer_pitchers_2017 = pd.read_csv('CSV_files/steamer/steamer_pitchers_{}.csv'.format(2017))\n",
    "    \n",
    "# only keep statistics we are interested in \n",
    "steamer_hitters_2017 = steamer_hitters_2017[['Name', 'AB', 'HR', 'R', 'RBI', 'SB', 'AVG', 'season']]\n",
    "steamer_pitchers_2017 = steamer_pitchers_2017[['Name', 'W', 'ERA', 'IP', 'K','SV', 'WHIP', 'season']]\n",
    "\n",
    "steamer_hitters_2017 = steamer_hitters_2017.rename(columns = {'season' : 'Season'})\n",
    "steamer_pitchers_2017 = steamer_pitchers_2017.rename(columns = {'season' : 'Season'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using a function defined previously, change names to lower case for uniformity\n",
    "steamer_pitchers_2017['Name'] = steamer_pitchers_2017['Name'].apply(lower_names)\n",
    "steamer_hitters_2017['Name'] = steamer_hitters_2017['Name'].apply(lower_names)\n",
    "\n",
    "steamer_pitchers_2017['First'], steamer_pitchers_2017['First_initial'], steamer_pitchers_2017['Last'] = \\\n",
    "    steamer_pitchers_2017['Name'].apply(split_names_first),steamer_pitchers_2017['Name'].apply\\\n",
    "        (split_names_first_initial),steamer_pitchers_2017['Name'].apply(split_names_last)\n",
    "steamer_pitchers_2017['Abbr_Name'] = steamer_pitchers_2017['First_initial'] + ' ' + steamer_pitchers_2017['Last']\n",
    "steamer_hitters_2017['First'], steamer_hitters_2017['First_initial'], steamer_hitters_2017['Last'] = \\\n",
    "    steamer_hitters_2017['Name'].apply(split_names_first),steamer_hitters_2017['Name'].apply\\\n",
    "        (split_names_first_initial),steamer_hitters_2017['Name'].apply(split_names_last)\n",
    "steamer_hitters_2017['Abbr_Name'] = steamer_hitters_2017['First_initial'] + ' ' + steamer_hitters_2017['Last']\n",
    "del steamer_hitters_2017['First'], steamer_hitters_2017['First_initial'], steamer_hitters_2017['Last']\n",
    "del steamer_pitchers_2017['First'], steamer_pitchers_2017['First_initial'], steamer_pitchers_2017['Last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign columns to the correct datatypes\n",
    "#steamer_hitters[\"AB\"] = pd.to_numeric(steamer_hitters.AB)\n",
    "steamer_hitters_2017[\"AB\"] = steamer_hitters_2017[\"AB\"].astype(str)\n",
    "steamer_hitters_2017[\"RBI\"] = steamer_hitters_2017[\"RBI\"].astype(int)\n",
    "steamer_hitters_2017[\"R\"] = steamer_hitters_2017[\"R\"].astype(int)\n",
    "steamer_hitters_2017[\"HR\"] = steamer_hitters_2017[\"HR\"].astype(int)\n",
    "steamer_hitters_2017[\"SB\"] = steamer_hitters_2017[\"SB\"].astype(int)\n",
    "steamer_hitters_2017[\"Season\"] = steamer_hitters_2017[\"Season\"].astype(int)\n",
    "\n",
    "steamer_pitchers_2017[\"K\"] = steamer_pitchers_2017[\"K\"].astype(int)\n",
    "steamer_pitchers_2017[\"W\"] = steamer_pitchers_2017[\"W\"].astype(int)\n",
    "steamer_pitchers_2017[\"Season\"] = steamer_pitchers_2017[\"Season\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Take a subset of the steamer dataframes to only include players in the actual statistics dataframes\n",
    "\n",
    "new_df_pitch_predict = find_names2(pitchersDF, steamer_pitchers_2017, [2017])\n",
    "new_df_hit_predict = find_names2(hittersDF, steamer_hitters_2017, [2017])\n",
    "steamer_pitchers_2017 = new_df_pitch_predict[0].append(new_df_pitch_predict[3])\n",
    "steamer_hitters_2017 = new_df_hit_predict[0].append(new_df_hit_predict[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ============================= CREATE DATAFRAMES OF ESPN PITCHER & HITTER PROJECTIONS ================================\n",
    "\n",
    "# Set up our hitter and pitcher Pandas DataFrames for 2017 ESPN method\n",
    "espn_hitters_2017 = pd.DataFrame()\n",
    "espn_pitchers_2017 = pd.DataFrame()\n",
    "\n",
    "# read in the csv file for 2017 and append it to the appropriate df\n",
    "\n",
    "espn_hitters_2017 = pd.read_csv('CSV_files/espn_hitters/espn_hitters_{}.csv'.format(2017))\n",
    "espn_pitchers_2017 = pd.read_csv('CSV_files/espn_pitchers/espn_pitchers_{}.csv'.format(2017))\n",
    "\n",
    "# keep only the stats we are interested in and rename columns to match our other dataframes\n",
    "espn_pitchers_2017 = espn_pitchers_2017[['name', '    K', '    W', '   IP', '   SV', '  ERA', ' WHIP', 'season']]\n",
    "espn_pitchers_2017.columns = ['Name', 'K', 'W', 'IP', 'SV', 'ERA', 'WHIP', 'Season']\n",
    "espn_hitters_2017 = espn_hitters_2017[['Player', '   AB', 'RBI', 'R','HR', 'SB', 'AVG', 'Season']]\n",
    "espn_hitters_2017.columns = ['Name', 'AB', 'RBI', 'R','HR', 'SB', 'AVG', 'Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert names to all lower case letters for uniformity\n",
    "espn_pitchers_2017['Name'] = espn_pitchers_2017['Name'].apply(lower_names)\n",
    "espn_hitters_2017['Name'] = espn_hitters_2017['Name'].apply(lower_names)\n",
    "\n",
    "espn_pitchers_2017['First'], espn_pitchers_2017['First_initial'], espn_pitchers_2017['Last'] = \\\n",
    "    espn_pitchers_2017['Name'].apply(split_names_first),espn_pitchers_2017['Name'].apply(split_names_first_initial),\\\n",
    "    espn_pitchers_2017['Name'].apply(split_names_last)\n",
    "espn_pitchers_2017['Abbr_Name'] = espn_pitchers_2017['First_initial'] + ' ' + espn_pitchers_2017['Last']\n",
    "espn_hitters_2017['First'], espn_hitters_2017['First_initial'], espn_hitters_2017['Last'] = \\\n",
    "    espn_hitters_2017['Name'].apply(split_names_first),espn_hitters_2017['Name'].apply(split_names_first_initial),\\\n",
    "    espn_hitters_2017['Name'].apply(split_names_last)\n",
    "espn_hitters_2017['Abbr_Name'] = espn_hitters_2017['First_initial'] + ' ' + espn_hitters_2017['Last']\n",
    "del espn_hitters_2017['First'], espn_hitters_2017['First_initial'], espn_hitters_2017['Last']\n",
    "del espn_pitchers_2017['First'], espn_pitchers_2017['First_initial'], espn_pitchers_2017['Last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take a subset of the espn dataframes to only include players in the actual statistics dataframes\n",
    "new_df_pitch_predict = find_names2(pitchersDF, espn_pitchers_2017, [2017])\n",
    "new_df_hit_predict = find_names2(hittersDF, espn_hitters_2017, [2017])\n",
    "\n",
    "espn_pitchers_2017 = new_df_pitch_predict[0].append(new_df_pitch_predict[3])\n",
    "espn_hitters_2017 = new_df_hit_predict[0].append(new_df_hit_predict[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop players without statistics\n",
    "\n",
    "# we want to use IP for the 2015 season, which is the only one that included this data\n",
    "espn_pitchers_2017 = espn_pitchers_2017.replace(np.nan, -100)\n",
    "\n",
    "#convert invalid data and drop it\n",
    "espn_pitchers_2017 = espn_pitchers_2017.replace(r'--', np.nan)\n",
    "espn_pitchers_2017 = espn_pitchers_2017.dropna()\n",
    "espn_pitchers_2017 = espn_pitchers_2017.replace(-100, np.nan)\n",
    "\n",
    "espn_hitters_2017 = espn_hitters_2017.replace(np.nan, -100)\n",
    "\n",
    "# convert invalid data and drop it\n",
    "espn_hitters_2017 = espn_hitters_2017.replace(r'--', np.nan)\n",
    "espn_hitters_2017 = espn_hitters_2017.dropna()\n",
    "espn_hitters_2017 = espn_hitters_2017.replace(-100, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign columns to the correct datatypes\n",
    "#espn_hitters[\"AB\"] = pd.to_numeric(espn_hitters.AB)\n",
    "#espn_hitters[\"AB\"] = espn_hitters[\"AB\"].astype(int)\n",
    "espn_hitters_2017[\"AB\"] = espn_hitters_2017[\"AB\"].astype(str)\n",
    "espn_hitters_2017[\"RBI\"] = espn_hitters_2017[\"RBI\"].astype(int)\n",
    "espn_hitters_2017[\"R\"] = espn_hitters_2017[\"R\"].astype(int)\n",
    "espn_hitters_2017[\"HR\"] = espn_hitters_2017[\"HR\"].astype(int)\n",
    "espn_hitters_2017[\"SB\"] = espn_hitters_2017[\"SB\"].astype(int)\n",
    "espn_hitters_2017[\"Season\"] = espn_hitters_2017[\"Season\"].astype(int)\n",
    "espn_hitters_2017[\"AVG\"] = espn_hitters_2017[\"AVG\"].astype(float)\n",
    "\n",
    "espn_pitchers_2017[\"IP\"] = espn_pitchers_2017[\"IP\"].astype(str)\n",
    "espn_pitchers_2017[\"ERA\"] = espn_pitchers_2017[\"ERA\"].astype(float)\n",
    "espn_pitchers_2017[\"WHIP\"] = espn_pitchers_2017[\"WHIP\"].astype(float)\n",
    "espn_pitchers_2017[\"K\"] = espn_pitchers_2017[\"K\"].astype(int)\n",
    "espn_pitchers_2017[\"W\"] = espn_pitchers_2017[\"W\"].astype(int)\n",
    "espn_pitchers_2017[\"Season\"] = espn_pitchers_2017[\"Season\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Fangraphs 2017\n",
    "# ========================== CREATE DATAFRAMES OF FANGRAPHS PITCHER & HITTER PROJECTIONS ==============================\n",
    "\n",
    "# Set up our hitter and pitcher pandas DataFrames for FanGraphs method\n",
    "fangraphs_hitters_2017 = pd.DataFrame()\n",
    "fangraphs_pitchers_2017 = pd.DataFrame()\n",
    "\n",
    "# for each year of projections read in the csv file and append it to the appropriate df\n",
    "df = pd.read_csv('CSV_files/fangraphs/fans_hitters_{}.csv'.format(2017))\n",
    "fangraphs_hitters_2017 = fangraphs_hitters_2017.append(df, ignore_index = True)\n",
    "df2 = pd.read_csv('CSV_files/fangraphs/fans_pitchers_{}.csv'.format(2017))\n",
    "fangraphs_pitchers_2017 = fangraphs_pitchers_2017.append(df2, ignore_index = True)\n",
    "\n",
    "# only keep statistics we are interested in \n",
    "fangraphs_hitters_2017 = fangraphs_hitters_2017[['Name', 'AB', 'HR', 'R', 'RBI', 'SB', 'AVG', 'season']]\n",
    "fangraphs_pitchers_2017 = fangraphs_pitchers_2017[['Name', 'W', 'ERA', 'IP', 'K','SV', 'WHIP', 'season']]\n",
    "fangraphs_hitters_2017 = fangraphs_hitters_2017.rename(columns = {'season' : 'Season'})\n",
    "fangraphs_pitchers_2017 = fangraphs_pitchers_2017.rename(columns = {'season' : 'Season'})\n",
    "\n",
    "\n",
    "fangraphs_hitters_2017.shape\n",
    "\n",
    "\n",
    "# using a function defined previously, change names to lower case for uniformity\n",
    "\n",
    "fangraphs_pitchers_2017['Name'] = fangraphs_pitchers_2017['Name'].apply(lower_names)\n",
    "fangraphs_hitters_2017['Name'] = fangraphs_hitters_2017['Name'].apply(lower_names)\n",
    "\n",
    "fangraphs_pitchers_2017['First'], fangraphs_pitchers_2017['First_initial'], fangraphs_pitchers_2017['Last'] = \\\n",
    "    fangraphs_pitchers_2017['Name'].apply(split_names_first),fangraphs_pitchers_2017['Name'].apply(split_names_first_initial),\\\n",
    "    fangraphs_pitchers_2017['Name'].apply(split_names_last)\n",
    "fangraphs_pitchers_2017['Abbr_Name'] = fangraphs_pitchers_2017['First_initial'] + ' ' + fangraphs_pitchers_2017['Last']\n",
    "fangraphs_hitters_2017['First'], fangraphs_hitters_2017['First_initial'], fangraphs_hitters_2017['Last'] = \\\n",
    "    fangraphs_hitters_2017['Name'].apply(split_names_first),fangraphs_hitters_2017['Name'].apply(split_names_first_initial),\\\n",
    "    fangraphs_hitters_2017['Name'].apply(split_names_last)\n",
    "fangraphs_hitters_2017['Abbr_Name'] = fangraphs_hitters_2017['First_initial'] + ' ' + fangraphs_hitters_2017['Last']\n",
    "\n",
    "del fangraphs_hitters_2017['First'], fangraphs_hitters_2017['First_initial'], fangraphs_hitters_2017['Last']\n",
    "del fangraphs_pitchers_2017['First'], fangraphs_pitchers_2017['First_initial'], fangraphs_pitchers_2017['Last']\n",
    "\n",
    "\n",
    "fangraphs_hitters_2017.shape\n",
    "\n",
    "\n",
    "# assign columns to the correct datatypes\n",
    "fangraphs_hitters_2017[\"AB\"] = fangraphs_hitters_2017[\"AB\"].astype(str)\n",
    "fangraphs_hitters_2017[\"RBI\"] = fangraphs_hitters_2017[\"RBI\"].astype(int)\n",
    "fangraphs_hitters_2017[\"R\"] = fangraphs_hitters_2017[\"R\"].astype(int)\n",
    "fangraphs_hitters_2017[\"HR\"] = fangraphs_hitters_2017[\"HR\"].astype(int)\n",
    "fangraphs_hitters_2017[\"SB\"] = fangraphs_hitters_2017[\"SB\"].astype(int)\n",
    "fangraphs_hitters_2017[\"Season\"] = fangraphs_hitters_2017[\"Season\"].astype(int)\n",
    "\n",
    "fangraphs_pitchers_2017[\"K\"] = fangraphs_pitchers_2017[\"K\"].astype(int)\n",
    "fangraphs_pitchers_2017[\"W\"] = fangraphs_pitchers_2017[\"W\"].astype(int)\n",
    "fangraphs_pitchers_2017[\"Season\"] = fangraphs_pitchers_2017[\"Season\"].astype(int)\n",
    "\n",
    "#Take a subset of the fangraphs dataframe to only include players in the actual statistics dataframes\n",
    "new_df_pitch_predict_2017 = find_names2(pitchersDF, fangraphs_pitchers_2017, [2017])\n",
    "new_df_hit_predict_2017 = find_names2(hittersDF, fangraphs_hitters_2017, [2017])\n",
    "fangraphs_pitchers_2017 = new_df_pitch_predict_2017[0].append(new_df_pitch_predict_2017[3])\n",
    "fangraphs_hitters_2017 = new_df_hit_predict_2017[0].append(new_df_hit_predict_2017[3])\n",
    "\n",
    "fangraphs_hitters_2017[\"AB\"] = pd.to_numeric(fangraphs_hitters_2017.AB)\n",
    "fangraphs_hitters_2017[\"AB\"] = fangraphs_hitters_2017[\"AB\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ============================= CREATE DATAFRAMES OF GURU PITCHER & HITTER PROJECTIONS ================================\n",
    "\n",
    "# Set up our hitter and pitcher Pandas dataframes for Guru method\n",
    "guru_hitters_2017 = pd.DataFrame()\n",
    "guru_pitchers_2017 = pd.DataFrame()\n",
    "\n",
    "# for each year of projections read in the csv file and append it to the apprpriate df\n",
    "ID=[2017]\n",
    "for i in ID:\n",
    "    df = pd.read_csv('CSV_files/guru/guru_hitters_{}.csv'.format(i))\n",
    "    guru_hitters_2017 = guru_hitters_2017.append(df, ignore_index = True)\n",
    "    \n",
    "    if i != 2015: # Special exception because Guru doesn't have projections for pitchers in 2015\n",
    "        df2 = pd.read_csv('CSV_files/guru/guru_pitchers_{}.csv'.format(i))\n",
    "        guru_pitchers_2017 = guru_pitchers_2017.append(df2, ignore_index = True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# only keep statistics we are interested in \n",
    "guru_hitters_2017 = guru_hitters_2017[['Name', 'AB', 'HR', 'R', 'RBI', 'SB', 'AVG', 'season']]\n",
    "guru_pitchers_2017 = guru_pitchers_2017[['Name', 'W', 'ERA', 'IP', 'K','SV', 'WHIP', 'season']]\n",
    "guru_hitters_2017 = guru_hitters_2017.rename(columns = {'season' : 'Season'})\n",
    "guru_pitchers_2017 = guru_pitchers_2017.rename(columns = {'season' : 'Season'})\n",
    "\n",
    "# drop null values\n",
    "guru_hitters_2017.dropna(inplace=True)\n",
    "guru_pitchers_2017.dropna(inplace=True)\n",
    "\n",
    "# replace -'s values with 0's\n",
    "guru_pitchers_2017['SV'] = guru_pitchers_2017['SV'].replace(\".*[\\-].* \",\"0\", regex=True).astype(int)\n",
    "guru_hitters_2017['HR'] = guru_hitters_2017['HR'].replace(\".*[\\-].*\", \"0\", regex=True).astype(int)\n",
    "guru_hitters_2017['SB'] = guru_hitters_2017['SB'].replace(\".*[\\-]*\", \"0\", regex=True).astype(int)\n",
    "guru_pitchers_2017['W'] = guru_pitchers_2017['W'].replace(\".*[\\-]*\", \"0\", regex=True).astype(int)\n",
    "\n",
    "# using a function defined previously, change names to lower case for uniformity\n",
    "\n",
    "guru_pitchers_2017['Name'] = guru_pitchers_2017['Name'].apply(lower_names)\n",
    "guru_hitters_2017['Name'] = guru_hitters_2017['Name'].apply(lower_names)\n",
    "\n",
    "guru_pitchers_2017['First'], guru_pitchers_2017['First_initial'], guru_pitchers_2017['Last'] = \\\n",
    "    guru_pitchers_2017['Name'].apply(split_names_first),guru_pitchers_2017['Name'].apply(split_names_first_initial),\\\n",
    "    guru_pitchers_2017['Name'].apply(split_names_last)\n",
    "guru_pitchers_2017['Abbr_Name'] = guru_pitchers_2017['First_initial'] + ' ' + guru_pitchers_2017['Last']\n",
    "guru_hitters_2017['First'], guru_hitters_2017['First_initial'], guru_hitters_2017['Last'] = \\\n",
    "    guru_hitters_2017['Name'].apply(split_names_first),guru_hitters_2017['Name'].apply(split_names_first_initial),\\\n",
    "    guru_hitters_2017['Name'].apply(split_names_last)\n",
    "guru_hitters_2017['Abbr_Name'] = guru_hitters_2017['First_initial'] + ' ' + guru_hitters_2017['Last']\n",
    "del guru_hitters_2017['First'], guru_hitters_2017['First_initial'], guru_hitters_2017['Last']\n",
    "del guru_pitchers_2017['First'], guru_pitchers_2017['First_initial'], guru_pitchers_2017['Last']\n",
    "\n",
    "# assign columns to the correct datatypes\n",
    "guru_hitters_2017[\"AB\"] = pd.to_numeric(guru_hitters_2017.AB)\n",
    "guru_hitters_2017[\"AB\"] = guru_hitters_2017[\"AB\"].astype(int)\n",
    "guru_hitters_2017[\"RBI\"] = guru_hitters_2017[\"RBI\"].astype(int)\n",
    "guru_hitters_2017[\"R\"] = guru_hitters_2017[\"R\"].astype(int)\n",
    "guru_hitters_2017[\"HR\"] = guru_hitters_2017[\"HR\"].astype(int)\n",
    "guru_hitters_2017[\"SB\"] = guru_hitters_2017[\"SB\"].astype(int)\n",
    "guru_hitters_2017[\"Season\"] = guru_hitters_2017[\"Season\"].astype(int)\n",
    "\n",
    "guru_pitchers_2017[\"K\"] = guru_pitchers_2017[\"K\"].astype(int)\n",
    "guru_pitchers_2017[\"W\"] = guru_pitchers_2017[\"W\"].astype(int)\n",
    "guru_pitchers_2017[\"Season\"] = guru_pitchers_2017[\"Season\"].astype(int)\n",
    "\n",
    "#Take a subset of the guru dataframe to only include players in the actual statistics dataframes\n",
    "seasons = [2017]\n",
    "\n",
    "#use the find names function defined earlier\n",
    "new_df_pitch = find_names2(pitchersDF, guru_pitchers_2017, seasons)\n",
    "new_df_hit = find_names2(hittersDF, guru_hitters_2017, seasons)\n",
    "\n",
    "guru_pitchers_2017 = new_df_pitch[0].append(new_df_pitch[3])\n",
    "guru_hitters_2017 = new_df_hit[0].append(new_df_hit[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sites = [espn_hitters_2017, fangraphs_hitters_2017, guru_hitters_2017, cbs_hitters_2017, steamer_hitters_2017]\n",
    "j = 0\n",
    "\n",
    "for i in marcel_hitters_2017['Name']:\n",
    "\n",
    "    rand = np.random.randint(0,5)\n",
    "    if i in list_sites[rand]['Name'].values:\n",
    "        new_sb = list_sites[rand][list_sites[rand]['Name'] == i]['SB'].values[0]\n",
    "        marcel_hitters_2017.set_value(j, 'SB', new_sb)\n",
    "        j+=1\n",
    "        j=j%307\n",
    "    elif i in list_sites[(rand+1)%len(list_sites)]['Name'].values:\n",
    "        rand += 1\n",
    "        rand = rand%len(list_sites)\n",
    "        new_sb = list_sites[rand][list_sites[rand]['Name'] == i]['SB'].values[0]\n",
    "        marcel_hitters_2017.set_value(j, 'SB', new_sb)\n",
    "        j+=1\n",
    "        j=j%307\n",
    "    else:\n",
    "        marcel_hitters_2017.set_value(j, 'SB', \\\n",
    "                        hittersDF[(hittersDF['Name']=='jose abreu') & (hittersDF['Season']==2016)]['actual_SB'].values[0])\n",
    "        j+=1\n",
    "        j=j%307"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning all of our dataframes we double checked that all the appropriate data was included, no unintended missing values or wrong values, and no duplicates. We now have a clean hitters and pitchers dataframe for the 6 prediction methods for 2010-2015, and a hitters and pitchers dataframe for the actual statistics of the years 2010-2016. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ================================= CREATE MASTER DATAFRAME OF 2017 PLAYER PROJECTIONS ================================\n",
    "\n",
    "# create empty lists to append to\n",
    "hitter_predictions_2017 = []\n",
    "pitcher_predictions_2017 = []\n",
    "\n",
    "# create lists of methods to loop through, one for hitters & one for pitchers\n",
    "hitters2017_method_list = [cbs_hitters_2017, espn_hitters_2017, fangraphs_hitters_2017, \\\n",
    "                       guru_hitters_2017, marcel_hitters_2017, steamer_hitters_2017]\n",
    "pitchers2017_method_list = [cbs_pitchers_2017, espn_pitchers_2017, fangraphs_pitchers_2017,\\\n",
    "                        guru_pitchers_2017, steamer_pitchers_2017]\n",
    "\n",
    "# create a method column in each dataframe\n",
    "for i in xrange(len(hitters2017_method_list)):\n",
    "    hitters2017_method_list[i][\"method\"] = float(i+1) \n",
    "for i in xrange(len(pitchers2017_method_list)):\n",
    "    if i <=4:\n",
    "        pitchers2017_method_list[i][\"method\"] = float(i)\n",
    "    else:\n",
    "        pitchers2017_method_list[i][\"method\"] = float(i+1)\n",
    "\n",
    "# loop through hitters projection dataframes\n",
    "for methodDF in hitters2017_method_list:\n",
    "    hitter_predictions_2017.append(methodDF)\n",
    "# concatenate master hitter projections list into pandas DataFrame\n",
    "hitter_predictions_2017 = pd.concat(hitter_predictions_2017)\n",
    "\n",
    "# loop through pitchers projection dataframes\n",
    "for methodDF in pitchers2017_method_list:\n",
    "    pitcher_predictions_2017.append(methodDF)\n",
    "# concatenate master pitcher projections list into pandas DataFrame\n",
    "pitcher_predictions_2017 = pd.concat(pitcher_predictions_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hitters\n",
    "\n",
    "hitter_predictions_2017 = hitter_predictions_2017.dropna()\n",
    "\n",
    "x_hitters2017 = hitter_predictions_2017[hitter_predictions_2017.columns.difference(['Abbr_Name', 'Name', 'Pos Summary',\\\n",
    "                        'Season', 'correct_AVG', 'correct_HR', 'correct_R', 'correct_RBI', 'correct_SB', 'AB', \\\n",
    "                        'Prediction_Season'])]\n",
    "\n",
    "to_predict_hitters_2017 = ['correct_AVG', 'correct_HR', 'correct_R', 'correct_RBI', 'correct_SB']\n",
    "\n",
    "\n",
    "# pitchers\n",
    "\n",
    "pitcher_predictions_2017 = pitcher_predictions_2017.dropna()\n",
    "\n",
    "x_pitchers2017 = pitcher_predictions_2017[pitcher_predictions_2017.columns.difference(['Abbr_Name', 'Name', 'Season',\\\n",
    "                'Prediction_Season', 'correct_ERA', 'correct_K', 'correct_W', 'correct_WHIP', 'IP', 'SV'])]\n",
    "\n",
    "to_predict_pitchers_2017 = ['correct_ERA', 'correct_K', 'correct_W', 'correct_WHIP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write cleaned data to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this will write the data frames below to csv files with the same name as the dataframes\n",
    "pd.DataFrame.to_csv(hittersDF, 'CSV_files/cleanCSV/hittersDF.csv')\n",
    "pd.DataFrame.to_csv(pitchersDF, 'CSV_files/cleanCSV/pitchersDF.csv')\n",
    "pd.DataFrame.to_csv(espn_hitters, 'CSV_files/cleanCSV/espn_hitters.csv')\n",
    "pd.DataFrame.to_csv(espn_pitchers, 'CSV_files/cleanCSV/espn_pitchers.csv')\n",
    "pd.DataFrame.to_csv(fangraphs_hitters, 'CSV_files/cleanCSV/fangraphs_hitters.csv')\n",
    "pd.DataFrame.to_csv(fangraphs_pitchers, 'CSV_files/cleanCSV/fangraphs_pitchers.csv')\n",
    "pd.DataFrame.to_csv(guru_hitters, 'CSV_files/cleanCSV/guru_hitters.csv')\n",
    "pd.DataFrame.to_csv(guru_pitchers, 'CSV_files/cleanCSV/guru_pitchers.csv')\n",
    "pd.DataFrame.to_csv(marcel_hitters, 'CSV_files/cleanCSV/marcel_hitters.csv')\n",
    "pd.DataFrame.to_csv(marcel_pitchers, 'CSV_files/cleanCSV/marcel_pitchers.csv')\n",
    "pd.DataFrame.to_csv(cbs_hitters, 'CSV_files/cleanCSV/cbs_hitters.csv')\n",
    "pd.DataFrame.to_csv(cbs_pitchers, 'CSV_files/cleanCSV/cbs_pitchers.csv')\n",
    "pd.DataFrame.to_csv(steamer_hitters, 'CSV_files/cleanCSV/steamer_hitters.csv')\n",
    "pd.DataFrame.to_csv(steamer_pitchers, 'CSV_files/cleanCSV/steamer_pitchers.csv')\n",
    "pd.DataFrame.to_csv(hitter_predictions, 'CSV_files/cleanCSV/hitter_predictions.csv')\n",
    "pd.DataFrame.to_csv(pitcher_predictions, 'CSV_files/cleanCSV/pitcher_predictions.csv')\n",
    "pd.DataFrame.to_csv(hitter_predictions_2017, 'CSV_files/cleanCSV/hitter_predictions_2017.csv')\n",
    "pd.DataFrame.to_csv(pitcher_predictions_2017, 'CSV_files/cleanCSV/pitcher_predictions_2017.csv')\n",
    "pd.DataFrame.to_csv(x_hitters, 'CSV_files/cleanCSV/x_hitters.csv')\n",
    "pd.DataFrame.to_csv(x_pitchers, 'CSV_files/cleanCSV/x_pitchers.csv')\n",
    "pd.DataFrame.to_csv(x_hitters2017, 'CSV_files/cleanCSV/x_hitters_2017.csv')\n",
    "pd.DataFrame.to_csv(x_pitchers2017, 'CSV_files/cleanCSV/x_pitchers_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(steamer_pitchers_2017, 'CSV_files/cleanCSV/steamer_pitchers_2017.csv')\n",
    "pd.DataFrame.to_csv(steamer_hitters_2017, 'CSV_files/cleanCSV/steamer_hitters_2017.csv')\n",
    "pd.DataFrame.to_csv(espn_hitters_2017, 'CSV_files/cleanCSV/espn_hitters_2017.csv')\n",
    "pd.DataFrame.to_csv(espn_pitchers_2017, 'CSV_files/cleanCSV/espn_pitchers_2017.csv')\n",
    "\n",
    "pd.DataFrame.to_csv(fangraphs_hitters_2017, 'CSV_files/cleanCSV/fangraphs_hitters_2017.csv')\n",
    "pd.DataFrame.to_csv(fangraphs_pitchers_2017, 'CSV_files/cleanCSV/fangraphs_pitchers_2017.csv')\n",
    "\n",
    "pd.DataFrame.to_csv(marcel_hitters_2017, 'CSV_files/cleanCSV/marcel_hitters_2017.csv')\n",
    "#note: we don't have marcel pitchers\n",
    "\n",
    "pd.DataFrame.to_csv(guru_hitters_2017, 'CSV_files/cleanCSV/guru_hitters_2017.csv')\n",
    "pd.DataFrame.to_csv(guru_pitchers_2017, 'CSV_files/cleanCSV/guru_pitchers_2017.csv')\n",
    "\n",
    "pd.DataFrame.to_csv(cbs_hitters_2017, 'CSV_files/cleanCSV/cbs_hitters_2017.csv')\n",
    "pd.DataFrame.to_csv(cbs_pitchers_2017, 'CSV_files/cleanCSV/cbs_pitchers_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
